<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">7827223</article-id><article-id pub-id-type="pmid">33440797</article-id><article-id pub-id-type="doi">10.3390/s21020471</article-id><article-id pub-id-type="publisher-id">sensors-21-00471</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Analysis of UAV-Acquired Wetland Orthomosaics Using GIS, Computer Vision, Computational Topology and Deep Learning</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-5693-5217</contrib-id><name><surname>Kentsch</surname><given-names>Sarah</given-names></name><xref ref-type="aff" rid="af1-sensors-21-00471">1</xref><xref ref-type="aff" rid="af2-sensors-21-00471">2</xref><xref rid="c1-sensors-21-00471" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-4417-1704</contrib-id><name><surname>Cabezas</surname><given-names>Mariano</given-names></name><xref ref-type="aff" rid="af3-sensors-21-00471">3</xref></contrib><contrib contrib-type="author"><name><surname>Tomhave</surname><given-names>Luca</given-names></name><xref ref-type="aff" rid="af2-sensors-21-00471">2</xref></contrib><contrib contrib-type="author"><name><surname>Gro&#x000df;</surname><given-names>Jens</given-names></name><xref ref-type="aff" rid="af2-sensors-21-00471">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8636-9009</contrib-id><name><surname>Burkhard</surname><given-names>Benjamin</given-names></name><xref ref-type="aff" rid="af2-sensors-21-00471">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-9748-7120</contrib-id><name><surname>Lopez Caceres</surname><given-names>Maximo Larry</given-names></name><xref ref-type="aff" rid="af1-sensors-21-00471">1</xref></contrib><contrib contrib-type="author"><name><surname>Waki</surname><given-names>Katsushi</given-names></name><xref ref-type="aff" rid="af4-sensors-21-00471">4</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-4521-9113</contrib-id><name><surname>Diez</surname><given-names>Yago</given-names></name><xref ref-type="aff" rid="af4-sensors-21-00471">4</xref><xref rid="c1-sensors-21-00471" ref-type="corresp">*</xref></contrib></contrib-group><aff id="af1-sensors-21-00471"><label>1</label>Faculty of Agriculture, Yamagata University, Tsuruoka 997-8555, Japan; <email>larry@tds1.tr.yamagata-u.ac.jp</email></aff><aff id="af2-sensors-21-00471"><label>2</label>Faculty of Natural Sciences, Leibniz Universit&#x000e4;t, 30167 Hannover, Germany; <email>luca.tomhave@kabelmail.de</email> (L.T.); <email>gross@phygeo.uni-hannover.de</email> (J.G.); <email>burkhard@phygeo.uni-hannover.de</email> (B.B.)</aff><aff id="af3-sensors-21-00471"><label>3</label>Brain and Mind Centre, University of Sydney, Sydney 2015, Australia; <email>mariano.cabezas@sydney.edu.au</email></aff><aff id="af4-sensors-21-00471"><label>4</label>Faculty of Science, Yamagata University, Yamagata 990-8560, Japan; <email>waki@sci.kj.yamagata-u.ac.jp</email></aff><author-notes><corresp id="c1-sensors-21-00471"><label>*</label>Correspondence: <email>sarah@tds1.tr.yamagata-u.ac.jp</email> (S.K.); <email>yago@sci.kj.yamagata-u.ac.jp</email> (Y.D.)</corresp></author-notes><pub-date pub-type="epub"><day>11</day><month>1</month><year>2021</year></pub-date><pub-date pub-type="collection"><month>1</month><year>2021</year></pub-date><volume>21</volume><issue>2</issue><elocation-id>471</elocation-id><history><date date-type="received"><day>27</day><month>11</month><year>2020</year></date><date date-type="accepted"><day>07</day><month>1</month><year>2021</year></date></history><permissions><copyright-statement>&#x000a9; 2021 by the authors.</copyright-statement><copyright-year>2021</copyright-year><license license-type="open-access"><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Invasive blueberry species endanger the sensitive environment of wetlands and protection laws call for management measures. Therefore, methods are needed to identify blueberry bushes, locate them, and characterise their distribution and properties with a minimum of disturbance. UAVs (Unmanned Aerial Vehicles) and image analysis have become important tools for classification and detection approaches. In this study, techniques, such as GIS (Geographical Information Systems) and deep learning, were combined in order to detect invasive blueberry species in wetland environments. Images that were collected by UAV were used to produce orthomosaics, which were analysed to produce maps of blueberry location, distribution, and spread in each study site, as well as bush height and area information. Deep learning networks were used with transfer learning and unfrozen weights in order to automatically detect blueberry bushes reaching True Positive Values (TPV) of 93.83% and an Overall Accuracy (OA) of 98.83%. A refinement of the result masks reached a Dice of 0.624. This study provides an efficient and effective methodology to study wetlands while using different techniques.</p></abstract><kwd-group><kwd>ArcGIS</kwd><kwd>big data</kwd><kwd>blueberries</kwd><kwd>deep learning</kwd><kwd>image analysis</kwd><kwd>orthomosaics</kwd><kwd>segmentation refinement</kwd><kwd>UAVs</kwd></kwd-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-21-00471"><title>1. Introduction</title><p>Recent changes in global climate conditions influence species composition and accelerating the presence of invasive plant species in natural environments. Species that spread outside their native habitat and rapidly and effectively adapt to new environments are known as invasive species [<xref rid="B1-sensors-21-00471" ref-type="bibr">1</xref>]. The spread of invasive species often benefits from ecosystem changes and habitat disturbances that weaken the natural species and open an ecological niche for invaders. Hence, invasive species can influence the biodiversity, thus limiting the growth of natural plant species due to a higher occurrence of an invasive species, which could lead to ecosystem degradation [<xref rid="B2-sensors-21-00471" ref-type="bibr">2</xref>]. The fast adaption to multiple stress factors in environments could also lead to a replacement of native species and it may increase economic costs due to production losses in agriculture and forestry [<xref rid="B3-sensors-21-00471" ref-type="bibr">3</xref>]. In Europe, 11% of the 12,000 identified species have caused damage to the economy, society, and the environment [<xref rid="B4-sensors-21-00471" ref-type="bibr">4</xref>]. Reference [<xref rid="B5-sensors-21-00471" ref-type="bibr">5</xref>] states that hundreds of invasive species find their pathways through horticulture, agriculture, etc., and the linearly increasing trend of invasive species numbers (from 1970 to 2007) indicates higher impacts of invasive species in the future. Reference [<xref rid="B6-sensors-21-00471" ref-type="bibr">6</xref>] pointed out that not only invasive species have an impact on native plants, since several factors often interact with the environment that influence species distributions. In recent years, the need to precisely understand the ecological impacts of invasive species in ecosystems has become a key in designing and prioritizing natural resource management approaches [<xref rid="B2-sensors-21-00471" ref-type="bibr">2</xref>], since the behaviour and impact of invasive species is still not well understood [<xref rid="B3-sensors-21-00471" ref-type="bibr">3</xref>,<xref rid="B7-sensors-21-00471" ref-type="bibr">7</xref>]. Furthermore, a high number of invasive plant are species spreading in natural environments, which increases the demand of management practices [<xref rid="B5-sensors-21-00471" ref-type="bibr">5</xref>].</p><p>In the past two decades, an explosive spread of North American blueberry hybrids (<italic>Vaccinium corymbosum</italic> x <italic>angustifolium</italic>) has been observed in several moors in the northern German geest area, endangering the natural development of these protected raised bog areas [<xref rid="B8-sensors-21-00471" ref-type="bibr">8</xref>]. The starting point of the spread has been almost exclusively located at existing or former commercial blueberry plantations [<xref rid="B9-sensors-21-00471" ref-type="bibr">9</xref>,<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>], which can be found near or in the immediate vicinity of bogs or former peat extraction areas, due to good soil and local climatic conditions. Most of the recipient habitats are pine forests and bogs in various stages of de- and regeneration. Because of these characteristics, the American Blueberry (<italic>Vaccinium angustifolium</italic> x <italic>corymbosum</italic>) has been classified as a potentially invasive neophyte by the <italic>German Federal Agency for Nature Conservation</italic> [<xref rid="B11-sensors-21-00471" ref-type="bibr">11</xref>]. After the degradation of wetland areas due to anthropogenic activities, protection programs, called "Moorschutzprogramme", were established by the state government of Lower Saxony for the conservation and the development of rare animal and plant communities in these areas [<xref rid="B12-sensors-21-00471" ref-type="bibr">12</xref>]. Furthermore, activities that could threaten the goals of the protection program are prohibited, which increases the difficulty of conducting relevant field studies [<xref rid="B12-sensors-21-00471" ref-type="bibr">12</xref>]. However, maintenance and development measures are needed in order to rehabilitate protected and relatively sensitive wetland areas, into which the invasive blueberry species <italic>Vaccinium corymbosum</italic> x angustifolium has migrated. In 2011, 20 counties in Lower Saxony reported stands of spontaneously growing blueberry bushes [<xref rid="B13-sensors-21-00471" ref-type="bibr">13</xref>]. The potential area that is occupied by spontaneously growing blueberry bushes can reach several square kilometres within a few years [<xref rid="B14-sensors-21-00471" ref-type="bibr">14</xref>]. Previous studies, as presented in [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>,<xref rid="B14-sensors-21-00471" ref-type="bibr">14</xref>], used grids in the field in order to plot the distribution of blueberry bushes within wetlands. Both of the studies focused on sites near blueberry cultivation areas, as the biggest spread was found in close proximity to blueberry plantations [<xref rid="B9-sensors-21-00471" ref-type="bibr">9</xref>]. Those studies show the limitations in the studied area and lack an overview. It is still unclear how far the blueberry bushes have already spread and in which areas they occur. In order to implement effective measures in these areas and minimise the disturbance of sensitive biotopes, it is necessary to locate the individual blueberry bushes as accurately and early as possible. In addition, the following questions arise: does a displacement of natural species occur and where should what measures be taken against a continuing invasion? According to [<xref rid="B14-sensors-21-00471" ref-type="bibr">14</xref>,<xref rid="B15-sensors-21-00471" ref-type="bibr">15</xref>], relatively simple counter measures can lead to good results and prevent further spread, especially when invasive blueberry bushes are identified early. Therefore, a suitable and non-invasive method for recording stock development and distribution is needed. A simple tool is needed to rapidly, cost-effectively, and precisely detect invasive species in wetlands to counteract their rapid reproduction. Wetlands are protected environments with limited ground accessibility making UAVs particularly appropriate for data collection. UAVs offer the possibility to cover large areas with high resolution images, and they have proved their usefulness in a variety of studies in agriculture [<xref rid="B16-sensors-21-00471" ref-type="bibr">16</xref>,<xref rid="B17-sensors-21-00471" ref-type="bibr">17</xref>] and forestry [<xref rid="B18-sensors-21-00471" ref-type="bibr">18</xref>,<xref rid="B19-sensors-21-00471" ref-type="bibr">19</xref>,<xref rid="B20-sensors-21-00471" ref-type="bibr">20</xref>]. Still, UAV images present challenges like the pre-pocessing of the data. Large amounts of data need to be processed, labeled, and annotated by experts, which is usually time consuming, before the data can be further analysed. The use of deep-learning techniques reduces the amount of time that is needed to extract information from the data, which increases the benefits for several applications.</p><p>Images that are acquired by UAVs can be analysed while using computer vision and GIS techniques. Important results can then be obtained by reducing the complexity contained in the images (using different image interpretation strategies) and the findings can be presented in elaborate visualisations [<xref rid="B21-sensors-21-00471" ref-type="bibr">21</xref>]. Persistent homology, a tool of topological data analysis, can help to understand complex datasets by analysing their large scale geometric features [<xref rid="B22-sensors-21-00471" ref-type="bibr">22</xref>]. In our study, we have used persistent homology to measure the spread of invasive species. Processing images and creating orthomosaics allow for a fast analysis of large amounts of data. Deep learning techniques additionally automatize classification and localisation processes, and make it possible to incorporate expert knowledge into the automatic image processing pipeline. This has the potential to increase the scale of the resulting studies to reach large regions that are significant in terms of country-level invasive species detection and management.</p><p>In this study, the incorporation of all the mentioned techniques from remote sensing, GIS, computer vision, computational topology, and artificial intelligence allows for us to study invasive species on a large scale, with minimum disturbances and the incorporation of expert knowledge. To the best of our knowledge, this is the first study that includes different techniques and UAV gathered data to increase the understanding of an invasive blueberry species in wetlands. Furthermore, locating and studying small bushes in large areas and at the single-bush level was done for the first time. Therefore, UAV-supported methods offer an efficient possibility to discover individual young plants on a large scale and detect propagation hotspots at an early stage.</p><p>The following objectives guided this study:<list list-type="simple"><list-item><label>(I)</label><p>To use UAV data in order to provide allometric statistics (height, area, and number) of invasive blueberry in large areas at bush level.</p></list-item><list-item><label>(II)</label><p>To use clustering techniques and persistent homology to quantitatively and qualitatively assess the spread of blueberry invasions.</p></list-item><list-item><label>(III)</label><p>To assess the potential of Deep learning to automatically segment blueberry bushes, initiating the possibility for even larger-scale studies.</p></list-item></list></p><sec><title>State of the Art</title><p>In recent years, remote sensing techniques have been used in various natural environments with the goal of reducing the need for in situ measurements [<xref rid="B23-sensors-21-00471" ref-type="bibr">23</xref>]. Low-cost data gathering, time saving, and larger study areas are the benefits. Furthermore, data can be directly used and processed within Geographical Information Systems (GIS) [<xref rid="B23-sensors-21-00471" ref-type="bibr">23</xref>]. This has been done successfully, for environmental studies [<xref rid="B24-sensors-21-00471" ref-type="bibr">24</xref>,<xref rid="B25-sensors-21-00471" ref-type="bibr">25</xref>,<xref rid="B26-sensors-21-00471" ref-type="bibr">26</xref>]. Closely related to the current work, Reference [<xref rid="B27-sensors-21-00471" ref-type="bibr">27</xref>] proposed using GIS as a synthesising tool in invasive species management approaches. Reference [<xref rid="B28-sensors-21-00471" ref-type="bibr">28</xref>] used satellite images of 1992 and 2002 in order to identify stress indicators and change detection in a wetland in Sri Lanka to quantify the conditions of the complex. The authors state that the inventory, mapping, and monitoring are needed to understand interactions in the ecosystem. Classification with the Maximum Likelihood Algorithm were performed, mapping and spatial analysis were used, and finally refined and verified with ground data. Their approach ([<xref rid="B28-sensors-21-00471" ref-type="bibr">28</xref>]) reached 86% accuracy and provided detailed analysis. GIS in combination with remote sensing data was found to be an effective methodology for investigating wetlands. Reference [<xref rid="B29-sensors-21-00471" ref-type="bibr">29</xref>] evaluated vegetation change detection while using the NDVI of remote sensing data and applied GIS in order to visualise the results. Landsat and Shuttle Radar Topography Missions were used to capture the Vellore District. Image interpretations were carried out using ERGDAS IMAGINE software in order to classify and detect changes in the vegetation. The differences in the NDVI values were used to analyse data sets of the years 2001 to 2006. The study provided information about the lowest decrease in the forest area by 6%, while agriculture land increased the most by 19%.</p><p>In comparison to satellite images UAV images provide a higher resolution and appear to be more suitable for wetland investigations, especially when focusing on invasive species. Higher resolution images allow for higher accuracies of image interpretations and feature extractions [<xref rid="B30-sensors-21-00471" ref-type="bibr">30</xref>]. Several studies using UAVs in wetlands have already been carried out [<xref rid="B31-sensors-21-00471" ref-type="bibr">31</xref>,<xref rid="B32-sensors-21-00471" ref-type="bibr">32</xref>,<xref rid="B33-sensors-21-00471" ref-type="bibr">33</xref>,<xref rid="B34-sensors-21-00471" ref-type="bibr">34</xref>]. Reference [<xref rid="B34-sensors-21-00471" ref-type="bibr">34</xref>] developed a method for detecting and mapping invasive species with UAVs. The authors acknowledged UAVs as suitable for monitoring eradication efforts in wetlands. Reference [<xref rid="B33-sensors-21-00471" ref-type="bibr">33</xref>] realized the higher efficiency in gathering valuable and accurate information in comparison to field studies, when using UAVs and computer vision techniques to enhance classifications and health assessments in wetlands. Gandhi et al. [<xref rid="B31-sensors-21-00471" ref-type="bibr">31</xref>] used UAV imagery for detecting invasive species and mapping their distribution and spread. This study also compared data from two years (2009 and 2011) and detected an increase of 19.07%, which was confirmed by field studies with a total agreement of 94% and shows the suitability of UAV imaging for this kind of application. Reference [<xref rid="B31-sensors-21-00471" ref-type="bibr">31</xref>] lanalysed the spread of <italic>Spartina alterniflora</italic> in Beihai in the years 2009 and 2011, using high resolution images acquired by UAVs. They captured images at a flight height of 800 m, generated orthomosiacs, performed multi-resolution segmentation by grouping homogenous pixels, and classified them. The target species was extracted by their pixel values. In a final step the accuracy was assessed and verified with field data by comparing three sample plots (a total of 166 samples) with the image results. A total accuracy of 94.0% could be achieved and, hence, provided information regarding an increasing spread of 19.07% from 2009 to 2011. The total infected area was, in 2011, 357.2 ha. Moreover, the image analysis provided the opportunity to identify areas with different levels of densities. Reference [<xref rid="B35-sensors-21-00471" ref-type="bibr">35</xref>] collected UAV images of <italic>Harrisia pomanensis</italic> in the Limpopo province of South Africa. An area of 87 ha was captured by images that were taken at a height of 800 to 817 m. Orthomosaics generated with Agisoft Photoscan and pixel as well as object-based classifiers were used. The classification results of supervised and unsupervised classifiers were assessed. The supervised classification outperformed the unclassified one, and the object-based approach outperformed the pixel-based one. The best accuracy achieved was 86.1%.</p><p>Given the sizes of the data sets used and the need to detect and classify parts of the images that only trained experts can confidently tell apart the use of deep learning in problems that are closely related to the current work is of common use. For example, a recent study [<xref rid="B36-sensors-21-00471" ref-type="bibr">36</xref>] used CNN (convolutional neutral network) in order to classify images from wetlands in an area of 700 km<inline-formula><mml:math id="mm1"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. They used a fully trained and fine-tuned CNN with a limited amount of data. A comparison of the CNN with random forest was performed to evaluate the capacity and classification accuracies of CNNs. Canadian wetlands were captured with two RapidEye images with 5 m resolution in 2015. The validation data were sampled in 2015 and 2016 and four wetland classes were identified using 1000 samples. The network was trained with patches and 30,000 iterations and then tested in a second step. The CNN outperformed the random forests and an overall accuracy of 94.82% was achieved, varying between 76.65% and 98.74%. Deep convolutional neural networks were also used by [<xref rid="B37-sensors-21-00471" ref-type="bibr">37</xref>] in order to classify AUV-acquired wetland images. The 677 m &#x000d7; 518 m study area was located in Southern Florida. The authors used processed orthomosaics and multi-view images and then compared them with the performances of random forests and support vector machines. Image segmentation was done with Trimble&#x02019;s eCognition by first segmenting objects, then extracting features, and finally training a classifier. The results of the study show the advantages of deep CNN, reaching an accuracy of 82.02%, when multi-view images were used and with lower accuracy when orthomosaics were used (71.69%). A similar approach was used in [<xref rid="B38-sensors-21-00471" ref-type="bibr">38</xref>]. 3800 images of the Brazilian national forest (Kaggle dataset) were used in order to identify <italic>hydrangea</italic> in the images. The dataset contained two-thirds of images, including the invasive species, a smaller fraction, where the invasive species appeared only in parts of the images, and a third small fraction that included no plants at all. The authors used three models: VGGNet, DenseNet, and Inception, which were pre-trained with ImageNet. Data augmentation was used and accuracies of 97.6% were reached.</p></sec></sec><sec id="sec2-sensors-21-00471"><title>2. Materials and Methods</title><sec id="sec2dot1-sensors-21-00471"><title>2.1. Study Area</title><p>The study area &#x0201c;Lichtenmoor&#x0201d; is located in a wetland region about 60 km northwest of Hanover in Lower Saxony, Germany (52&#x000b0;43<inline-formula><mml:math id="mm2"><mml:mrow><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>06.2<inline-formula><mml:math id="mm3"><mml:mrow><mml:msup><mml:mrow/><mml:mrow><mml:mo>&#x02033;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> N 9&#x000b0;20<inline-formula><mml:math id="mm4"><mml:mrow><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>41.5<inline-formula><mml:math id="mm5"><mml:mrow><mml:msup><mml:mrow/><mml:mrow><mml:mo>&#x02033;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> E) (<xref ref-type="fig" rid="sensors-21-00471-f001">Figure 1</xref>).The total size of the moor area is 38 km<inline-formula><mml:math id="mm6"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> [<xref rid="B39-sensors-21-00471" ref-type="bibr">39</xref>]. Post industrial peat cutting characterises the central area of the studied wetland. As a subsequent use, some former peat cutting areas have been rewetted with the aim of regenerating raised bogs. In the surrounding area, parts of the Lichtenmoor have been designated as nature reserves. Former hand peat cutting sites are located at the edges and in parts of the nature reserves. Agricultural areas dominate the remaining areas, mostly grassland, dry to moist moorland forests, scrubby heather and moorland degeneration stages, pioneer stages of moorland rewetting, and peat extraction areas under cultivation. The case study area covers a total area of 62 ha and it is located in the central part of the Lichtenmoor region. To the northeast, it borders a pine plantation, while at its southwest border current peat extraction areas are located. Blueberry plantations can be found throughout the Lichtenmoor, especially on the outskirts of the localities Lichtenhorst, Heemsen, Sonnenborstel, and Steimbke.</p></sec><sec id="sec2dot2-sensors-21-00471"><title>2.2. Characteristics of the Blueberry Species</title><p>Blueberries have been cultivated in commercial plantations in Lower Saxony since the early 1930&#x02019;s [<xref rid="B14-sensors-21-00471" ref-type="bibr">14</xref>]. Since then, the area under cultivation has steadily increased. In 2005, the area with blueberry cultivation in Lower Saxony was approximately 1400 hectares [<xref rid="B13-sensors-21-00471" ref-type="bibr">13</xref>]. In nature, blueberries are mainly distributed by birds and small mammals, who spread the seeds. Once established, plants can spread in a vicinity by clonal growth and the high regeneration potential of blueberries favours a strong spread [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>]. The species prefers acidic locations, such as pine forests or wetlands. Especially, raised bogs in their degeneration stage provide ideal habitat conditions for invasive blueberries [<xref rid="B14-sensors-21-00471" ref-type="bibr">14</xref>]. Thus, blueberries are growing increasingly wild in neighbouring areas. References [<xref rid="B9-sensors-21-00471" ref-type="bibr">9</xref>,<xref rid="B14-sensors-21-00471" ref-type="bibr">14</xref>] found a correlation between the density of blueberries and the distance to blueberry plantations; a maximum distance of 1700 m was recorded. Near cultivated areas, the feral blueberries form dense shrub stands with height of up to 2&#x02013;3 m and have a ground coverage of up to &#x0003e;60%. With increasing distance, the degree of coverage decreases rapidly [<xref rid="B8-sensors-21-00471" ref-type="bibr">8</xref>,<xref rid="B9-sensors-21-00471" ref-type="bibr">9</xref>,<xref rid="B13-sensors-21-00471" ref-type="bibr">13</xref>]. Since these studies were already conducted in the last millennium, a larger distribution must be expected today. Reference [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>] describes a distribution of blueberry bushes over 4 ha in the &#x0201c;Kr&#x000e4;henmoor&#x0201d;, where the maximum distance to the plantation was identified at 100 m. Blueberry bushes are low and can reach a height of 60 cm, but, occasionally, tall species can be found with a height of 3 m [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>]. In the course of the increasing growth and dense shrub structures, other ground vegetation is displaced, since it cannot exist under the shade of blueberries. Other presumed effects of blueberry cultivation are reduced evaporation rates and the influence on nutrient cycles in wetlands, which, in turn, can have an impact on existing plant species. Therefore, human interventions are necessary to protect the sensitive rare structures and characteristic plants of wetlands [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>].</p></sec><sec id="sec2dot3-sensors-21-00471"><title>2.3. Data Collection and Pre-Processing</title><p>Image collection was performed by using a DJI phantom 4 UAV in autumn 2018, because of the seasonal red colouring of blueberry leaves, which makes them easily detectable (<xref ref-type="fig" rid="sensors-21-00471-f002">Figure 2</xref>). For sites B1 to B4, 490 to 584 images were collected, while 1346 images were taken for B6. The flight height was 50 m and front and side overlaps of 80% were chosen. These images were then processed while using the Metashape software [<xref rid="B40-sensors-21-00471" ref-type="bibr">40</xref>] to align images in order to produce one orthomosaic and DEM (Digital Elevation Model) for each site (<xref ref-type="fig" rid="sensors-21-00471-f001">Figure 1</xref>). It should be mentioned that an overlap between the sites B1 to B4 was chosen, so the east and west borders of the orthomosaics B1 to B4 are overlapping. All of the obtained orthomosaics were annotated while using the open source image manipulation software GIMP [<xref rid="B41-sensors-21-00471" ref-type="bibr">41</xref>]. For three of them (B1, B2, and B3), the whole orthomosaic was annotated and each pixel was given one of the following six labels: blueberries, trees, yellow bushes, soil, water, and dead trees (<xref ref-type="fig" rid="sensors-21-00471-f001">Figure 1</xref>). The class trees contains pine trees (<italic>Pinus sylvestris</italic>), the class yellow bushes contains shrubby birches (predominantly <italic>Betula pubescens</italic>, secondarily <italic>Betula pendula</italic>). Binary layers for each of the six classes were created for each of the three orthomosaics while using the pixel-level labels. These annotations were based on colour, shape, and context information contained in the orthomosaics. In the last two orthomosaics (B4 and B6), only blueberry bushes were annotated.</p><p>In order to train deep learning models to detect blueberry bushes orthomosaics annotated with all of the aforementioned labels were needed. Therefore, only B1 to B3 were used in the deep learning section of this study. These three orthomosaics, as well as the corresponding annotated binary layers were divided into axis-parallel patches of side length = 100 (hereafter "patch size"). This value was determined by taking the sizes of the blueberry bushes in the images, which ranged from 20 to 100 pixels in radius, into account. The classes in each patch were stored in a separate <italic>label</italic> list. In general, patches contained more than one class and, therefore, our problem can be defined as a multi-label patch classification problem.</p><sec id="sec2dot3dot1-sensors-21-00471"><title>2.3.1. Data Processing Using Arcgis</title><p>This section deals with data processing performed with ArcGIS pro 2.4.1 and python in order to identify parts of the orthomosaic containing blueberry bushes, in order to visualize them and analyse their characteristics. ArcGIS is a Geographic Information System software that visualises and comprehends geographic data. The software provides over 1000 tools to analyse real world data, including UAV-acquired images. The mapping options allow to visualise the gathered data within the correct location in an eligible base map. The primary purpose of this study was to provide information about the location and distribution of invasive blueberry species and map them for management.</p><p>In this context, the positions of the blueberry bushes in the five orthomosaics were digitised by hand as point data in an ArcGIS shapefile and several analytical tools were then used (<xref ref-type="fig" rid="sensors-21-00471-f002">Figure 2</xref>). The <italic>kernel density</italic> tool functions were used to calculate the magnitude-per-unit area from the blueberry points. Smaller search radiuses were used to show a detailed density raster. The tool <italic>integrate</italic> was used to group blueberry bushes that fall into a specified distance, as specified distance, 3 and 6 m were used. With the tool <italic>collect event</italic>, the number of points which were integrated before, were summarized in a new layer. Those steps were necessary to perform an <italic>optimized hotspot analysis</italic> of the blueberry abundance with the blueberry point shapefile. The hotspot analysis identifies the significant difference between the neighbourhood of a feature in comparison to the extent of the respective study area. Is the value of a feature significantly higher, it is considered to be a hotspot and the tool provides a feature map with three levels of confidence (90%, 95%, and 99%). As input for the hot spot analysis, the created layer of the tool <italic>collect events</italic> was used and analysis field counts were chosen. Furthermore, it also indicates the significantly lower features.</p><p>On the basis of the annotation made for all orthomosaics, several simple python codes and ArcGIS were used to perform image analysis. Pixels were counted for all orthomosaics, as well as all annotated layers. The number of black pixels in the annotated layers were specifically counted in order to obtain the percentage and area in m<inline-formula><mml:math id="mm7"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> per class. Additionally, the overall area presented in the orthomosaics was calculated in hectares. Because the focus of this study was on the blueberry bushes, several statistical values were generated: the number of blueberry bushes was counted and the number of blueberry bushes per ha was calculated for each orthomosaic. Additionally, the total area, as well as the area per blueberry bush, were computed in m<inline-formula><mml:math id="mm8"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. Furthermore, the proportion of blueberry bushes in relation to the vegetation was calculated in %. Finally, height values were computed on the basis of DEMs, annotations of the blueberry bushes, and annotations of ground points per site. Ground points were annotated close to blueberry bushes in order to increase the accuracy of the computed height. Maximum height values were estimated in a first analysis and the median height in a second analysis to evaluate the results.</p></sec></sec><sec id="sec2dot4-sensors-21-00471"><title>2.4. Persistent Homology</title><p>Persistent homology provides topological information of complex datasets [<xref rid="B42-sensors-21-00471" ref-type="bibr">42</xref>] at different spatial resolutions. This information deals with the connectivity of nearby points and it can be computed in different dimensions. For the purpose of this study, we worked with 0-D persistent homology (usually expressed in the form of H0 diagrams). H0 homology can be seen as growing disk at uniform radius-increase speed around pre-defined data points. In order to use this tool, we first discredited the manually annotated blueberry regions by uniformly sampling them. Subsequently, the radius around each sample point was increased to grow blueberry bush regions. When two blueberry regions were merged because of the expansion, one of the regions was considered to be dead because it was absorbed by the other region. As time passed, the number of connected blueberry regions decreased, and finally all of the regions were connected in one region.</p><p>The H0 diagram shows the change in the connectivity of the blueberry bushes by plotting the time/radius when blueberry regions get connected. False regions that were produced by our sampling of the annotated regions were discarded and only those parts of the diagrams that were obtained after all sampling points in each region had been joined together were considered. Based on this outcome, the radius was calculated until 1%, 10%, 50%, and 90% of the blueberry regions were connected and plotted. The diagram will vary greatly, depending on the number and position of blueberry bushes in the input image.</p></sec><sec id="sec2dot5-sensors-21-00471"><title>2.5. Deep Learning Techniques</title><p>Deep learning is a trending field of machine learning that focuses on fitting large models with millions of parameters for a variety of tasks, such as image classification and segmentation. These approaches have been rapidly gaining attention in computer vision tasks, due to their recently increased accuracy. Deep learning models commonly learn from examples in a supervised manner. First, an <italic>architecture</italic> or a graph of connected nodes is defined. These nodes are often grouped in <italic>layers</italic> that perform a specific operation, and the combination of a large number of layers is referred to as a <italic>deep neural network</italic> (<bold>DNN</bold>).The typology of the nodes, the number of nodes per layer and the connections between them determine the behaviour of the network. In general, two main types of nodes are used: linear nodes, expressed as matrix multiplications and nodes that introduce non-linear functions (such as the sigmoid function). The weights in linear nodes are usually initialised with random values following a specific distribution. Afterwards, the network is given samples of the data, known as <italic>training samples</italic>, which contain instances of the problem (i.e., image intensities) with their corresponding solutions (i.e., labels). These samples are iteratively run through the network in order to evaluate its current accuracy and the weights are updated following an optimization process.</p><p>In this study, DNNs were used to locate and identify the six classes that are defined in <xref ref-type="sec" rid="sec2dot3-sensors-21-00471">Section 2.3</xref>, with a focus set on the blueberry class. The basis for this deep learning approach is described in previous studies [<xref rid="B20-sensors-21-00471" ref-type="bibr">20</xref>,<xref rid="B43-sensors-21-00471" ref-type="bibr">43</xref>], which led to the use of the algorithms that are described in this section.</p><p>Our approach is based on a patch classification model that uses the patches of 100 &#x000d7; 100 pixels described in <xref ref-type="sec" rid="sec2dot3-sensors-21-00471">Section 2.3</xref>. A patch of orthomosaic B1 and B3 covered; therefore, 700 cm &#x000d7; 700 cm and a patch of orthomosaic B2 500 cm &#x000d7; 500 cm. For each patch, a list containing the class labels was created from the binary maps for each class. This classification is usually referred as multi-label, since each input patch might contain different labels (i.e., a part of the patch may contain soil, while other parts of the same patch could also contain bushes or blueberries).</p><p>Deep neural networks for classification have two major components: a feature extraction stage and a prediction stage. At the first stage, convolutional operators are trained in order to extract salient and meaningful features (such as texture) while at the second stage these features are used to predict the final labels for the given input patch or image. In order to train general and robust feature extractors, a large pool of heterogeneous images with different properties (lightning, colour, view, etc.) is needed to capture all of the possible image variabilities. However, as proven by our previous work [<xref rid="B20-sensors-21-00471" ref-type="bibr">20</xref>,<xref rid="B43-sensors-21-00471" ref-type="bibr">43</xref>], transfer learning is a useful tool for image analysis applications, where the training dataset is too small to properly train these feature extractors from scratch.</p><p>In our case, only three different orthomosaics are available; hence, we decided to use transfer learning by loading a pre-trained ResNet50 architecture with weights from ImageNet, due to its accuracy and reduced training time. ImageNet is one of the largest image databases for image classification research, with more than 80,000 labels and at least 1000 images for each label.</p><p>In order to perform the evaluation of the proposed model, two of the three orthomosaics were used for training and validation and the third one was used for testing. This cross-validation strategy is usually referred to as a leave-one-out strategy. All of the orthomosaics were used once for testing, training, and validation by rotating them for each experiment. Patches from the testing orthomosaic were not included for training or validation to avoid data leakage during training.</p><p>Two main approaches were used in order to obtain a higher detection rate for the blueberry class:<list list-type="bullet"><list-item><p>Data augmentation is a commonly used strategy in deep learning and it can increase the size of the training datasets without the need to collect new data. In this case, data augmentation was used to generate new synthetic patches of the blueberry class, which was the less frequent class (see <xref ref-type="sec" rid="sec3dot2-sensors-21-00471">Section 3.2</xref> for details). Six image transformations to augment the data were used: up/down and left/right flips; small central rotations with a random angle, in order to simulate different perspectives of the bushes; Gaussian blurring of the images, which simulates blurring due to the movement of the UAV; linear and small contrast changes, which can represent different light and shadow conditions and localised elastic deformations. In order to implement this transformations we used the &#x0201c;imgaug&#x0201d; library [<xref rid="B44-sensors-21-00471" ref-type="bibr">44</xref>].</p></list-item><list-item><p>Loss functions are used to compute the accuracy of the network and update their parameters. By giving different weights to different classes, their importance can be changed during training. In this study, two loss functions were used; the first function checks if a patch contains a blueberry or not, while the second one checks the fraction of blueberry pixels inside the patch. The optimal training settings followed the ones that were used in our previous study [<xref rid="B43-sensors-21-00471" ref-type="bibr">43</xref>].</p></list-item></list></p><p>We considered labels for all the patches used and the relation between (1) predicted values resulting from our algorithm and (2) real values as stated in the manually-annotated ground truth in order to assess the predictive power of our algorithms.</p><p>We then broke all of the patches into the usual classification categories of:<list list-type="bullet"><list-item><p><bold>True Positives</bold> or TP, predicted to contain the blueberry class and also marked in the ground truth as containing them.</p></list-item><list-item><p><bold>False Positives</bold> or FP, predicted to contain the blueberry class but NOT marked as such in the ground truth. These patches correspond to over-prediction errors where the algorithm &#x0201c;sees&#x0201d; the blueberry class when it is not really there.</p></list-item><list-item><p><bold>True Negatives</bold> or TN, not containing the blueberry class in the prediction or in the ground truth.</p></list-item><list-item><p><bold>False Negatives</bold> or FN, not predicted to contain blueberries, but actually being marked as containing them in the ground truth. These patches correspond to under-prediction errors where existing blueberry instances are missed by the algorithm.</p></list-item></list></p><p>We used the two following metrics (True Positive Rate or Sensitivity and Accuracy) in order to summarize the occurrences of the four categories.
<disp-formula id="FD1-sensors-21-00471"><label>(1)</label><mml:math id="mm9"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mspace width="2.em"/><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Finally, we modified the algorithm to present the results in a way that was more usable for end-users. The 100 &#x000d7; 100 patches used for prediction managed to capture most of the occurrences of the Blueberry class (see <xref ref-type="sec" rid="sec3dot2-sensors-21-00471">Section 3.2</xref> for details). However, these rather large patches also included large areas that actually contained no blueberries. While expert users could easily use these results as a starting point in order to quickly identify the exact location of blueberry bushes, we felt that refining our prediction using smaller patches would make their work faster, while also providing clearer information for non-expert users. Consequently, we divided each of the predicted 100 &#x000d7; 100 patches into 16 25 &#x000d7; 25 patches, re-sampled each of these newly-made smaller patches to the image size that is used by our DNN and re-classified them. This resulted in a refined result made up of 25 &#x000d7; 25 patches. This process had the disadvantage that, if errors were made, some of the correctly predicted blueberry pixels might be lost. In order to evaluate this issue, we considered the <italic>TP</italic>, <italic>FP</italic>, <italic>TN</italic>, and <italic>FP</italic> status of each pixel in each patch and measured the percentage of positive pixels that were covered by our predicted patches as well as the Dice coefficient that gave us an indication of the relative weight of blueberry pixels inside of our predicted patches:<disp-formula id="FD2-sensors-21-00471"><label>(2)</label><mml:math id="mm10"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p></sec></sec><sec sec-type="results" id="sec3-sensors-21-00471"><title>3. Results</title><p>This section is divided in two parts: the first part of the analysis focused on the manual annotations of the wetland vegetation and, most specifically, of the blueberry bushes. GIS, computer vision, and persistent homology were used to describe and quantify the characteristics of the blueberry invasion in all of our test sites. In the second part of this section, the results of Deep learning techniques are presented. In this case, our goal was to assess to what extent these technologies can be used to automatically generate the annotations that were used in the first part to characterise the invasion. The general workflow can be seen in <xref ref-type="fig" rid="sensors-21-00471-f003">Figure 3</xref>.</p><sec id="sec3dot1-sensors-21-00471"><title>3.1. Analysis of the Blueberry Invasion</title><p>In this part of the study, we focused on characterising and measuring the blueberry invasion of the wetland.</p><sec id="sec3dot1dot1-sensors-21-00471"><title>3.1.1. Quantitative Analysis of Blueberry Bushes</title><p>The distribution of the classes in the images (blueberries, trees, yellow bushes, soil, water, and dead trees, see <xref ref-type="sec" rid="sec2dot3-sensors-21-00471">Section 2.3</xref>) was analysed and the state of the invasion was assessed by gathering information regarding the areas of the sites, the numbers of blueberry bushes, and the average area per bush.</p><p>One important aspect was to calculate the area of blueberry bushes within the orthomosaics. The area covered by the orthomosaics varied between 10.6 to 12.5 ha, only B6 was larger with 15.5 ha (<xref rid="sensors-21-00471-t001" ref-type="table">Table 1</xref>). Together with the annotations made for B1 to B3 the area of each class was calculated (<xref ref-type="fig" rid="sensors-21-00471-f004">Figure 4</xref>). As can be seen in the orthomosaic (<xref ref-type="fig" rid="sensors-21-00471-f001">Figure 1</xref>) the main part of the image represented soils. This was validated by the area calculations: with 76% of the orthomosaic B2 and 89% of B3, soil represents the highest values of all classes. The second smaller pie shows the living vegetation varying between 4.7% in B1 to 18.6% in B2. Out of the living vegetation, 8.2% (B2), 15.0% (B3), and 21.1% (B1) are blueberry bushes. In most of the orthomosaics blueberries were the least frequent class (with 1 to 1.5%).</p><p>The number of blueberry bushes varied from 235 in orthomosaic B6 to 687 in B2 (<xref rid="sensors-21-00471-t001" ref-type="table">Table 1</xref>). The site areas of orthomosaic B1, B3 and B4 were similar, while orthomosaic B6 is the largest site containing the least number of blueberry bushes and orthomosaic B2 contains the greatest number of blueberry bushes in the smallest area. The ratio could be confirmed by calculating the blueberry bushes per ha (<xref rid="sensors-21-00471-t001" ref-type="table">Table 1</xref>). In another step, annotations were used in order to calculate the total area covered by blueberry bushes. In orthomosaic B6, an area of 278.07 m<inline-formula><mml:math id="mm11"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> was covered by blueberry bushes, which represents the smallest area and it resulted in an area of 1.18 m<inline-formula><mml:math id="mm12"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> per blueberry bush. The largest area was covered by blueberry bushes in B2 with 1885.51 m<inline-formula><mml:math id="mm13"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. The average size of the bushes were similar for B2 and B3. In site B1 the average size of blueberry bushes was the highest with 3.55 m<inline-formula><mml:math id="mm14"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, while the covered area was third lowest with 1331.41 m<inline-formula><mml:math id="mm15"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>.</p><p>Because the covered area and the average size of the bushes could be calculated, the next point of interest was the area and height per blueberry bush (<xref ref-type="fig" rid="sensors-21-00471-f005">Figure 5</xref>). Bushes were grouped into six to smaller than 10 m<inline-formula><mml:math id="mm16"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> and over 10 m<inline-formula><mml:math id="mm17"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> because the percentage of blueberries decreased towards larger cover areas. B1 and B2 had approximately 30 bushes between 6 and 8 m<inline-formula><mml:math id="mm18"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, which was the maximum of all sites. The mean areas were computed for all orthomosaics, indicating that B1 had a high number of large bushes with a mean area of 3.57 m<inline-formula><mml:math id="mm19"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. The smallest blueberry bushes could be found in orthomosaic B6 indicated a mean value of 1.18 m<inline-formula><mml:math id="mm20"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. In general, most of the blueberry bushes showed areas of up to 2 m<inline-formula><mml:math id="mm21"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, a lower amount distributed between 2 and 4 m<inline-formula><mml:math id="mm22"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> and the lowest numbers distributed in areas greater than 4 m<inline-formula><mml:math id="mm23"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. B1 was an exception, with around 10% per class over 4 m<inline-formula><mml:math id="mm24"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. The highest areas calculated range between 17 to 25 m<inline-formula><mml:math id="mm25"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, with B1 containing four bushes in that range and 27 with areas above 10 m<inline-formula><mml:math id="mm26"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. The lowest areas were found to be less than 10 cm<inline-formula><mml:math id="mm27"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> for B1/B4 and approximately 15 cm<inline-formula><mml:math id="mm28"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> for all other orthomosaics.</p><p>A similar distribution can be seen in <xref ref-type="fig" rid="sensors-21-00471-f005">Figure 5</xref>, where the number of blueberry bushes were plotted against the height. Classes were chosen for each 0.5 m starting with 0 m up to lower than 3.5 m and more than 3.5 m. This distribution was chosen due to the characteristics of shallow blueberry bushes that reach 60 cm and tall species that reach 3 m. Regarding the maximum height, no height was computed for 2.3% (B1) up to 15.5% (B6) while the numbers were higher when the median height was considered (11.0% for B1 up to 35.2% for B6). In general, the median height values were higher for the classes 0 m and 0.5 m in comparison to the maximum height, while the values are lower from 0.5 m.The lowest height values started from 0.01 m (B6), 0.03 m (B1), 0.07 m (B3/4), and 0.1 m (B2) for both max. and median height. In general, the maximum and the median height distribution of the orthomosaics was similar. Almost all of the blueberry bushes in orthomosaic B6 were within the class &#x0003c; 0.5 (83.3%). In B1 the number of blueberry bushes in this same class was 79% and 15.2% was between 0.5 and &#x0003c;1 m, which was similar to B6. Orthomosaic B2 to B4 showed a Poisson distribution, whereby B2 had the highest number in <inline-formula><mml:math id="mm29"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> m with 21.2 m, while 41.6 of the blueberry bushes in B4 had the highest value in &#x0003c;0.5 m. Furthermore, in B2 and B3, more than 50% of the blueberry bushes reached heights between 1 m and 3.5 m (57% and 57.7%).It has to be considered that the area was calculated on the shapefiles in ArcGIS, while our developed python code was used in order to calculate the height of the blueberry bushes. Because the input for the code was the annotations of the blueberry bushes that were stored as a PNG file, those bushes that were close together were grouped. Therefore, the height values were not always calculated for an individual bush, which resulted in a different number of blueberry bushes per site: 309 (B1), 519 (B2), 461 (B3), 394 (B4), and 219 (B6).</p></sec><sec id="sec3dot1dot2-sensors-21-00471"><title>3.1.2. Analysis of Spread Patterns</title><p>In a second step of our quantitative analysis of the blueberry invasion, the concentration, density, and spread patterns were examined. GIS and persistent homology were used to assess these issues. Characterisations of concentrations and densities can indicate the number of blueberry bushes within a given region of the orthomosaic, which exceeds a simple location because the distribution of the bushes can be analysed precisely. Clustering bushes and mapping densities further increase the understanding of the distribution. Together with the persistent homology and hotspot analysis, the spread can be defined for all orthomosaics, which helps to characterise the invasion.</p><p>The first step was to cluster blueberry bushes by using specified distances, of which 3 and 6 m were chosen, due to the calculated area of the blueberry bushes. The average diameter was considered to be 2 m for the different sites, and therefore a diameter of 3 m was found to be appropriate to especially group blueberry bushes that were close to each other. The results of both distances were compared and they are listed in <xref rid="sensors-21-00471-t002" ref-type="table">Table 2</xref>. When blueberry bushes were located in a range of 3 m, they were clustered with the following results. From orthomosaic B3 to B1, 35.51% to 39.87% were clustered. The highest number of clustered bushes were 33 in B3, followed by 25 in B2 and 10 in B1. In comparison to B1 to B3, B4 and B6 had around 28.3 % clusters with three and more blueberry bushes. The highest number within a cluster was nine for B4 and 13 for B6. After increasing the range to 6 m, the number of blueberry bushes clustered in the group 3 or more bushes increased to 69.57%, which is more than 30 percentage points. B1, B3, and B4 had a similar increase of around 15 percentage points and reached 56.63 % in B1, 50.43% in B3 and 44.35 in B6. With less than 10 percentage points, 37.68 % of the blueberry bushes were grouped together with more than three bushes.</p><p>Based on the point shapefiles of the blueberry bushes, density maps were generated to see how the bushes were distributed within the map. <xref ref-type="fig" rid="sensors-21-00471-f006">Figure 6</xref> provides three examples of the orthomosaics B1 to B3. Areas with a high density are marked in red and low densities in dark green. Orthomosaic B1 has one large density spot in the northwestern part of the map, while the southeast direction the density decreases with only single or paired bushes. Orthomosaic B2 shows four density spots. Two smaller ones were located in the northwest, a larger spot is in the middle of the orthomosaic and a final one in the southeast. The space between the middle and southeast spot is covered by blueberry bushes, which was similar to the distribution of B3. In orthomosaic B4, nearly the whole area is covered with green to reddish colours. There are three dense spots in the northwest, two spots in the middle and one in the southeast. In comparison to B2 and B3, the spots are smaller. Orthomosaic B6 covers a larger area than all other orthomosaics, but only three density spots could be identified in the middle of the orthomosaic. There were smaller groups of blueberry bushes along the borders of the orthomosaic, and single ones are distributed close to the groups of bushes.</p><p>Another analysis focused on the point analysis to generate a map of hotspot areas in order to analyse the spread of the blueberry species. The point analysis used the manually marked blueberry bushes to identify where the proximity of the bushes was significantly different (hot and cold), and to quantify those that were not identified as significantly different. In B1, two 90% confidence hotspots were found in the north. 21 clusters were identified to be 90% significantly different from the study area. The hotspots in B2 were concentrated in the south-easternmost part of the orthomosaic. 26 clusters (out of 220) were significantly different to the study area with a confidence interval of 99%. These points contained all of the bushes located in the south-easternmost part of the orthomosaic. In B3 16 out of the 214 clusters fell into the 99% confidence interval, all located in the south-east of the orthomosaic. The same characteristic was found in B4. 23 clusters out of 248 were found to be significant with a 99% confidence and seven points with 90% to 95% confidence. B4 was the only orthomosaic containing two points considered to be cold spots with 90% confidence in the centre of the orthomosaic.</p><p>Finally, the persistent homology was performed, as described in <xref ref-type="sec" rid="sec2dot3dot1-sensors-21-00471">Section 2.3.1</xref>. The radius was plotted against the fused region, as can be seen in <xref ref-type="fig" rid="sensors-21-00471-f007">Figure 7</xref>. The orthomosaics B2, B3, and B4 show a similar trend, while B1 and B6 also follow a different, but similar, trend to each other. B2 is the first orthomosaic, where 1% of the blueberry bushes were fused with a radius of 386 and B1 needed the largest radius with a value of 497. In all orthomosaics the radius needed to fuse up to 10% of the blueberry bushes is similar with values between 415 and 557. There is a small gap of approximately 150 between B3 (945), B6 (998), B1 (824), B2 (768), and B4 (831), when 50% of the blueberry bushes were fused. The radius needed to fuse 90% for B1 and B6 are 3279 and 3611, while, for B2 to B4, it is 1610 to 1709.</p></sec></sec><sec id="sec3dot2-sensors-21-00471"><title>3.2. Deep Learning Results</title><p>In this section, we describe the usefulness of deep learning techniques in order to automatically determine the location of blueberry bushes in our data. As stated in <xref ref-type="sec" rid="sec2dot5-sensors-21-00471">Section 2.5</xref>, a widely used network (ResNet50) was chosen and two main aspects were studied: how the data balance affects the final classification results and whether using transfer learning resulted in improved results. Several experiments were presented in a previous study [<xref rid="B43-sensors-21-00471" ref-type="bibr">43</xref>]; however, we will only focus on the optimal results for this current study.</p><p>Regarding transfer learning, <italic>unfrozen</italic> ImageNet [<xref rid="B45-sensors-21-00471" ref-type="bibr">45</xref>] weights were considered to initialise the network. When the model weights are <italic>unfrozen</italic>, all of the layers are normally trained and, thus, all the weights are updated. Regarding the data balance, the blueberry patch loss was weighted eight times that of the soil class, and four times the amount of the other classes. We also performed upsampling of the blueberry class by creating 12 new samples for each patch, as detailed in <xref ref-type="sec" rid="sec2dot5-sensors-21-00471">Section 2.5</xref>. Finally, the soil class was downsampled to 50% of its original number of patches.</p><p>Because three orthomosaics were available, a leave-one-mosaic-out cross validation approach was applied in order to evaluate the results. One of the orthomosaics was used for training, another for validation and the last one for testing. In order to ensure that all orthomosaics were used at least once for training, validation, and testing, we rotated them accordingly. This section presents the averages results for the TPR and the accuracy results of the three testing stages that correspond to each orthomosaic.</p><p>By using the optimal settings that are presented in this section, the model improved from a low TPR value of 63.8% for the blueberry class when no data balancing was applied to a value of 93.39%. In both cases, the overall accuracy for all classes remained similar (98.83% and 98.10%, respectively). Furthermore, it could be observed that unfreezing the weights had a positive effect on the TPR. The best TPR value for the <italic>frozen</italic> weights was 37.12% without data augmentation while maintaining an overall high accuracy value of 98.01%. However, when using high data augmentation with <italic>frozen</italic> weights, the best TPR value of 87.99% was obtained at the expense of a lower overall accuracy value of 75.20%. These results suggest that ImageNet weights can be used for this problem, but they need to be updated (and <italic>unfrozen</italic>) when using data augmentation to focus on blueberry bushes due to the differences in images.</p><p>Regarding the refinement step of the algorithm, <xref ref-type="fig" rid="sensors-21-00471-f008">Figure 8</xref> presents an example of the obtained results. For most of the predicted patches, the segmentation that was obtained with the refined version of the algorithm is much closer to the manual annotation. However, in a few cases, some of the bushes that had originally been detected are missed after the refinement. <xref rid="sensors-21-00471-t003" ref-type="table">Table 3</xref> presents the detailed results of these two issues.</p><p>On the one hand, the Dice coefficient, which evaluates the overlap and number of non-GT pixels that are contained in the predicted patches, improved significantly with the refinement algorithm from values around 0.2 to values in the 0.5&#x02013;0.6 range. On the other hand, the ratio of GT pixels that are covered by the mask, which ranges from 0.88 to 0.95 for the non-refined mask was slightly inferior in the refined version (0.78 to 0.87).</p></sec></sec><sec sec-type="discussion" id="sec4-sensors-21-00471"><title>4. Discussion</title><p>The applied methodology used UAVs to gather information in a restricted access area. Techniques from several research areas were then applied in order to gain knowledge regarding the distribution and properties of the bushes of the invasive blueberry species. In this section, the results that are presented in <xref ref-type="sec" rid="sec3-sensors-21-00471">Section 3</xref> are interpreted in order to assess the stage of the invasion in each of the mosaics.</p><sec id="sec4dot1-sensors-21-00471"><title>4.1. Difficulties with Data</title><p>Blueberry plants show a characteristic red leaf colour in autumn, which make them easily recognisable and identifiable in comparison to other classes of vegetation. Both a simple identification and segmentation by colour were proposed and applied in one of the first segmentation approaches. However, partly visible soil with reddish tones constrained blueberry identification. This problem was especially critical for small blueberry bushes. In autumn, the leaf colours can vary between red, red with a yellowish tone, and partly black. This caused challenges for the annotations and for the deep learning algorithm, since the number of blueberry images was already low in comparison to the other classes and it made the colour approach not usable for this study. Further complications were given by light conditions during image taking. When the blueberry bushes had brighter red colours due to sun light, it was difficult to distinguish them from the ground. Bushes, which were located in the shadows, especially the ones that had a predominately black colour, were barely recognisable.</p><p>The analysis presented some difficulties in the calculations of the height and surface area of the blueberry bushes. The main problems to determine bush height are occlusions, due to nearby trees and difficulties due to dense floor covering vegetation. As the cluster analysis shows, the high density of blueberry bushes in some areas and their proximity increased the possibilities that the bushes were partly covered and the whole bush area was not visible, as already pointed out by [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>]. Furthermore, bushes were often located close to trees that have canopies that can cover most of a blueberry bush. The areas calculated for the blueberry bushes, exceeding 4&#x02013;5 m<inline-formula><mml:math id="mm30"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, indicated that there has to be more than one bush, which was difficult to identify in the images, as well as for calculating the height. Wetland regions, imaged in the orthomosaics are grassland and covered with dense hassocks. Therefore, the soil is often not visible and the ground annotations often represent the height of the hassocks, which resulted in values of 0 m maximum height and even more bushes showed a value of 0 m, when the median height was calculated for smaller bushes, especially in B4 and B6. Therefore, it is assumed that the hassocks can reduce the real height of the bushes by 30 cm. However, the calculated height values exceeded 3 m, which is unusual for the blueberry species that are studied here. There were errors produced when the annotations contained parts of an overlapping tree canopy, which increased the maximum height. The median height was resistant to outlier values. When ground areas were annotated, the median generally decreased the height values, especially for small bushes. Annotations of the ground need to be set carefully, since the wetland was uneven and depressions could increase the height values of the blueberry bushes. Furthermore, the differences between the max. height and median height can be influenced by the structure of the bush canopy. Because of these difficulties, a correlation between the height and area values of blueberry bushes was not considered, but a comparison of the distribution of these values showed that the distribution was similar and the bush area was larger than the height.</p><p>Even though these values are estimations, the applied methodology gave a good overview over a large study area, which cannot otherwise be done by extensive field measurements due to wetland protection regulations. Therefore, despite the difficulties, the achieved results emphasised the following discussion of applications and the qualitative use of the introduced methodology.</p></sec><sec id="sec4dot2-sensors-21-00471"><title>4.2. Application in Landscape Management</title><p>The collection of high resolution images and the gathered information can help to map and visualise the findings of this study. This information can be used in order to easily establish management measures against the further invasion of alien species into the wetlands, as pointed out in previous studies [<xref rid="B31-sensors-21-00471" ref-type="bibr">31</xref>,<xref rid="B35-sensors-21-00471" ref-type="bibr">35</xref>].</p><p>The area that was occupied by blueberry bushes was low in terms of the studied area (covering 1 to 1.5 %), which is lower than the identified 3 to 5% in [<xref rid="B15-sensors-21-00471" ref-type="bibr">15</xref>]. However, when only the living vegetation was considered, the number of blueberry bushes was found to increase from 8.2 up to 21.1%. These percentages can be considered to be very high, due to the fact that the species is invasive and it does not belong to this sensitive ecosystem. B6 has the largest area and it contains the smallest number of blueberry bushes, with the smallest height and area values measured. Therefore, the invasion seems to be in an early stage and it should be easier to manage. Nevertheless, as shown by persistent homology and the high number of single bushes after clustering, bushes were wide spread, which increases the area where measures against the blueberry bushes need to be considered. The hotspot analysis and density map of B6 indicated that there are some bushes, which are concentrated in a dense spot in the middle of the area and distributed from there homogeneously. These findings allowed for determining that the progress of the blueberry bushes into this site is low.</p><p>B1 has a similar distribution, while the number of blueberry bushes per hectare is doubled in comparison to B6. The density map showed high densities in the northern part of the orthomosaic and a gradual decrease of blueberry bushes in the southern direction, which was confirmed by the hotspot analysis. The density of the bushes was higher than in B6, but, as indicated by the persistent homology, the spread was greater. This indicates that the blueberries invaded but did not reach every region of the site. Furthermore, the blueberry bushes in B1 have the largest bush area within all studied sites. The identified bushes maturity suggests that the blueberry species has invaded the area a long time ago. Because the density map provided the information that the blueberry bushes are mainly distributed in the north, there must be conditions in the south, which prevented further spread.</p><p>In comparison, B2, B3, and B4 showed a high spread in the southern direction, because blueberry bushes of various size were found everywhere and there were higher concentration areas and several spreading centres. These findings can be confirmed with the persistent homology and density map, indicating a high progress of the invasion. The three orthomosaics seem to have a homogeneous distribution and a gradual change to lower numbers in the southern direction. However, the significant differences that were found by the hotspot analysis indicate that there are conditions that influence the distribution of the blueberry bushes, as in site B1. In addition, all three orthomosaics show an area with a small density of bushes, which can probably be explained by the high water content in the soil correlated with unsuitable conditions regarding plant growth. The invasion of the blueberry species was characterised as such and far advanced for B2 to B4. Only B4 has smaller bushes that cover a smaller area, which suggests that the invasion is less advanced than for B2 and B3. The spread will probably increase there in the following years.</p><p>Furthermore, the distribution of the blueberry bushes can be connected to the proximity of trees, especially in B1 to B3, where bushes are mainly found around pine trees and shrubby birches, since birds use these as rest areas and mainly distribute seeds where they rest. An exception is B4, where the trees are located next to depressions that are filled with water, which confirms the unsuitable living conditions for blueberry species. In general, it seems that more blueberry bushes occur when the density of the living vegetation is higher, which can be explained by better living conditions and a better distribution through birds.</p><p>To sum up the results and interpretations, it was found that B6 showed an early stage of invasion. B1 shows an advanced stage of invasion with limitations in the south, while B2 to B4 show a critical, advanced stage of invasion, since the blueberry bushes can be found in the whole study site. The methodology used here helped to assess the stages of invasion.</p><p>Our study shows a method for helping preserve a sustainable and adaptive conservation of natural ecosystems. Together with further expert interpretations, a deeper understanding of wetland ecosystems can be achieved [<xref rid="B30-sensors-21-00471" ref-type="bibr">30</xref>]. The calculated properties, height and area, are indices that can be used for plant growth monitoring [<xref rid="B46-sensors-21-00471" ref-type="bibr">46</xref>], and, therefore, they provide useful information for the practical management of wetlands.</p></sec><sec id="sec4dot3-sensors-21-00471"><title>4.3. Contribution to Invasive Blueberry Studies in Wetlands</title><p>Previous studies were conducted to identify areas of blueberry bush invasions. The first studies were done by [<xref rid="B9-sensors-21-00471" ref-type="bibr">9</xref>,<xref rid="B14-sensors-21-00471" ref-type="bibr">14</xref>] covering up to 12.5 km<inline-formula><mml:math id="mm31"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> with estimations of blueberry bush coverage areas. Another study focusing on the invasive blueberry species was presented by [<xref rid="B15-sensors-21-00471" ref-type="bibr">15</xref>], studying an area of 4.7 ha, which is nine times smaller than the area that was studied in our work. Reference [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>] studied an area of 230 ha and characterised the blueberry invasion. The author conducted 11 days of fieldwork in order to capture the information regarding the cover area of blueberry bushes. The study area is less in our work with 63 ha, but, in comparison to the manual fieldwork, image capturing only took half a day. The pre-processing step needed the longest time, about 4 to 5 h per orthomosaic, since manual annotations were done in the beginning of the work. Therefore, the presented workflow of our study reduces the amount of time for gathering information significantly. The characteristics that were provided by [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>] are mainly focused on the blueberry bush cover area, which were 16% of the 230 ha. Other characteristics were provided by general statements about average heights and clustering behaviours. Our study provided height and area measurements for each blueberry bush, which has not been done in previous studies. Based on the orthomosaics, further measures, like hot spot analysis, density calculations, and spread measures, could be performed in order to characterise the blueberry invasion in much more detail than previous studies have shown [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>,<xref rid="B15-sensors-21-00471" ref-type="bibr">15</xref>]. Furthermore, refs. [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>,<xref rid="B15-sensors-21-00471" ref-type="bibr">15</xref>] stated a high probability of loss of identification during fieldwork due to the density of the bushes in certain areas near former blueberry plantations, which were therefore predominantly investigated. In comparison to the mentioned studies, our work presents an objective grading, a precise cover area and each bush was detected in the captured high-resolution images. This information is essential in order to compare both the invasion and monitoring in different areas.</p></sec><sec id="sec4dot4-sensors-21-00471"><title>4.4. Automatic Masks Generation</title><p>Deep learning techniques were used in order to assess whether DNN can be used to automatically detect the presence of blueberry bushes. Since the manual annotation of the blueberry bushes is the most time-consuming step of this workflow, this has the potential to greatly extend the range of studies. The results in <xref ref-type="sec" rid="sec3dot2-sensors-21-00471">Section 3.2</xref> show that the ResNet50 network succeeded at the classification tasks associated to our problem and that the best results were obtained by re-training the whole network. In this respect, relying on pre-trained weights from ImageNet to solve our problem after minor re-training of the last layer is suboptimal. A dataset must be large enough to re-train the full networks. In our case, this meant using images that were taken from three orthomosaics covering a total of 33 hectares.</p><p>At the same time, the results also quantify how a data imbalance may result in a network that classifies most of the patches correctly, wven if the blueberry bushes were mainly misclassified. To address this problem, data augmentation as well as a loss function that took into account the number of pixels for each class were used to influence the weights which helped to reduce bias of the training towards the correct classification of blueberry bushes.</p><p>Wetland image classification was performed by [<xref rid="B36-sensors-21-00471" ref-type="bibr">36</xref>,<xref rid="B37-sensors-21-00471" ref-type="bibr">37</xref>] identifying four and six classes, reaching an overall accuracy of 94.82% and 82.02%. Transfer learning which was only applied in [<xref rid="B36-sensors-21-00471" ref-type="bibr">36</xref>] showed the effectiveness of this technique for natural environment studies, when the dataset is large enough. Interestingly, the best result of [<xref rid="B37-sensors-21-00471" ref-type="bibr">37</xref>] was obtained when using multi-view images. We will consider this type of images in our future work. A similar approach to detect invasive species was used by [<xref rid="B38-sensors-21-00471" ref-type="bibr">38</xref>]. Their approach applied deep learning with data augmentation and transfer learning. Their highest accuracy was 97.6%, which is slightly lower than our overall accuracies of 98.83% and 98.10%. It is important to consider that, in [<xref rid="B38-sensors-21-00471" ref-type="bibr">38</xref>], the dataset was mainly composed of images of the invasive species, while, in our case, only 2.64% of the generated patches contained the invasive species. This illustrates the effectiveness of the techniques used in our approach to overcome the imbalance in our dataset.</p><p>The results of the automatic classification were used in order to map the invasive species, which is an important first step, whereby a refined segmentation is essential to effectively determine the exact location of plant invasions [<xref rid="B35-sensors-21-00471" ref-type="bibr">35</xref>]. The deep learning applications used classified images, and a refined mask provided the blueberry bush locations. The refinement step was necessary in this application, since most of the blueberry bushes are small. Hence, the refined mask offered a more precise localisation of the blueberry bushes. Even though not all bushes were found and some soil areas were misclassified as blueberry bushes, the refined mask could significantly reduce the time of manual annotations and provide maps of the studied area. Increasing the amount of blueberry data can help to optimize the classification accuracy and the localisation of blueberry bushes. This will be considered in our future research.</p><p>The generation of automatic annotation masks, as performed here, will allow for large scale studies with a minimum of disturbances in the studied environment. Therefore, UAVs and image analysis provide accurate and cost-effective surveys that are needed when studying invasive species [<xref rid="B31-sensors-21-00471" ref-type="bibr">31</xref>]. The used techniques provided more information than that gathered by previous field surveys in wetland areas [<xref rid="B10-sensors-21-00471" ref-type="bibr">10</xref>,<xref rid="B14-sensors-21-00471" ref-type="bibr">14</xref>].</p></sec><sec id="sec4dot5-sensors-21-00471"><title>4.5. Limitation and Future Works</title><p>The presented work provided a methodology to analyse invasive species from UAV images. Nevertheless, we faced limitations regarding the data that are described in <xref ref-type="sec" rid="sec4dot1-sensors-21-00471">Section 4.1</xref>. The autumn season seemed to be a good timing for image taking, but the difficulties regarding the varying colour of the blueberry bushes should be taken into account more carefully. Image taking could be done when the weather is cloudy and not windy, as suggested in previous studies [<xref rid="B47-sensors-21-00471" ref-type="bibr">47</xref>,<xref rid="B48-sensors-21-00471" ref-type="bibr">48</xref>]. The chosen flight height of 50 m resulted in high-resolution images, which created heavy orthomosaics. The resolution was reduced to 5&#x02013;7 cm/pixel to be able to use image processing software. This led to difficulties in identifying blueberry bushes and their properties. For the future, different flight settings can be tested, as presented in [<xref rid="B49-sensors-21-00471" ref-type="bibr">49</xref>,<xref rid="B50-sensors-21-00471" ref-type="bibr">50</xref>], especially smaller flight areas and a reduced flight height can help to increase the resolution and precision of the results of blueberry bush properties.</p><p>The use of deep learning proved to be effective for this problem, but also challenging. As in all artificial intelligence approaches, a sufficient number of images that represent the variability of the desired target is necessary in order to train a supervised model that is usable in practice (in the current studies, this amounted to images that corresponded to 33 hectares). Furthermore, with the size of the current blueberry bush data in these images, careful use of data augmentation as well as a dedicated balancing approach was necessary. In order to improve the detection of blueberry bushes, a larger training dataset would likely be needed. For instance, because blueberry bushes are often planted for blueberry production, those fields could offer a good opportunity to collect new images.</p><p>Therefore, the detailed mapping within this study can further improve the results of the current status of the blueberry species invasion. Repeated data collection in the same area, as planned, will provide a year-to-year comparison, which will allow for the monitoring and analysis of the ongoing spread in the wetlands. Changes will be easily detectable within the wetlands and the studied blueberry species without disturbances of vulnerable plant and animal species and habitats, as already mentioned by [<xref rid="B30-sensors-21-00471" ref-type="bibr">30</xref>,<xref rid="B35-sensors-21-00471" ref-type="bibr">35</xref>].</p></sec></sec><sec sec-type="conclusions" id="sec5-sensors-21-00471"><title>5. Conclusions</title><p>In this paper, we introduced a multi-disciplinary methodology to quantitatively evaluate the role of plant species in ecosystems, including invasive species. The use of UAVs makes the approach applicable, even in restricted access areas and it increases the total area that can be studied, greatly exceeding the range of existing field studies. We used this methodology to gather information regarding wetland vegetation. Simple and time-saving methods were applied to classify vegetation and provide information about the properties of the invasive blueberry species found in our study site. The distribution of blueberry bushes was analysed in terms of their density, clustering, and spread. The relative importance of blueberries in the wetland was analysed (number of bushes, bush area, and bush height). This information was transformed into location, density, and hotspot maps to provide advanced visualization tools. Deep learning techniques were used in order to automatically detect and segment blueberry bushes, opening the possibility to further extend the range of similar studies.</p></sec></body><back><ack><title>Acknowledgments</title><p>The publication of this article was funded by the Open Access Fund of the Leibniz Universit&#x000e4;t Hannover. We thank Angie Faust for language corrections and Thomas Beuster (&#x000d6;SSM - Ecological protection station Steinhuder Meer) for the opportunity to take aerial photography in the study site and for his helpful contributions to the ecology of blueberries in the Lichtenmoor.</p></ack><fn-group><fn><p><bold>Publisher&#x02019;s Note:</bold> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><notes><title>Author Contributions</title><p>S.K., M.C., L.T., J.G., B.B., K.W., M.L.L.C. and Y.D., conceived the conceptualization and methodology, supported the writing&#x02014;review and editing. S.K., M.C. and Y.D. developed the software, performed the validation, investigation and writing&#x02014;original draft preparation. S.K., M.C. and Y.D. carried out formal analysis. S.K. was in charge of the visualisations. S.K., and J.G. administrated the data. J.G, B.B., M.L.L.C. and Y.D. supervised the project and provided resources. J.G., B.B. and Y.D. directed the project administration. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Funding</title><p>This research received no external funding.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The data presented in this study are available on request from the corresponding author.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-21-00471"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prentis</surname><given-names>P.J.</given-names></name><name><surname>Wilson</surname><given-names>J.R.</given-names></name><name><surname>Dormontt</surname><given-names>E.E.</given-names></name><name><surname>Richardson</surname><given-names>D.M.</given-names></name><name><surname>Lowe</surname><given-names>A.J.</given-names></name></person-group><article-title>Adaptive evolution in invasive species</article-title><source>Trends Plant Sci.</source><year>2008</year><volume>13</volume><fpage>288</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1016/j.tplants.2008.03.004</pub-id><pub-id pub-id-type="pmid">18467157</pub-id></element-citation></ref><ref id="B2-sensors-21-00471"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Py&#x00161;ek</surname><given-names>P.</given-names></name><name><surname>Richardson</surname><given-names>D.M.</given-names></name></person-group><article-title>Invasive Species, Environmental Change and Management, and Health</article-title><source>Annu. Rev. Environ. Resour.</source><year>2010</year><volume>35</volume><fpage>25</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1146/annurev-environ-033009-095548</pub-id></element-citation></ref><ref id="B3-sensors-21-00471"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pimentel</surname><given-names>D.</given-names></name><name><surname>Zuniga</surname><given-names>R.</given-names></name><name><surname>Morrison</surname><given-names>D.</given-names></name></person-group><article-title>Update on the environmental and economic costs associated with alien-invasive species in the United States</article-title><source>Ecol. Econ.</source><year>2005</year><volume>52</volume><fpage>273</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1016/j.ecolecon.2004.10.002</pub-id></element-citation></ref><ref id="B4-sensors-21-00471"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caffrey</surname><given-names>J.</given-names></name><name><surname>Baars</surname><given-names>J.R.</given-names></name><name><surname>Barbour</surname><given-names>J.</given-names></name><name><surname>Boets</surname><given-names>P.</given-names></name><name><surname>Boon</surname><given-names>P.</given-names></name><name><surname>Davenport</surname><given-names>K.</given-names></name><name><surname>Dick</surname><given-names>J.</given-names></name><name><surname>Early</surname><given-names>J.</given-names></name><name><surname>Edsman</surname><given-names>L.</given-names></name><name><surname>Gallagher</surname><given-names>C.</given-names></name><etal/></person-group><article-title>Tackling Invasive Alien Species in Europe: The Top 20 Issues</article-title><source>Manag. Biol. Invasions</source><year>2014</year><volume>5</volume><fpage>1</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.3391/mbi.2014.5.1.01</pub-id></element-citation></ref><ref id="B5-sensors-21-00471"><label>5.</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Rabitsch</surname><given-names>W.</given-names></name><name><surname>Genovesi</surname><given-names>P.</given-names></name></person-group><article-title>Invasive Alien Species Indicators in Europe; EEA Technical Report; 2012</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://op.europa.eu/en/publication-detail/-/publication/0e70dca6-0213-4420-b04a-8951cb9a0df7/language-en">https://op.europa.eu/en/publication-detail/-/publication/0e70dca6-0213-4420-b04a-8951cb9a0df7/language-en</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2021-01-08">(accessed on 8 January 2021)</date-in-citation></element-citation></ref><ref id="B6-sensors-21-00471"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Didham</surname><given-names>R.K.</given-names></name><name><surname>Tylianakis</surname><given-names>J.M.</given-names></name><name><surname>Hutchison</surname><given-names>M.A.</given-names></name><name><surname>Ewers</surname><given-names>R.M.</given-names></name><name><surname>Gemmell</surname><given-names>N.J.</given-names></name></person-group><article-title>Are invasive species the drivers of ecological change?</article-title><source>Trends Ecol. Evol.</source><year>2005</year><volume>20</volume><fpage>470</fpage><lpage>474</lpage><pub-id pub-id-type="doi">10.1016/j.tree.2005.07.006</pub-id><pub-id pub-id-type="pmid">16701420</pub-id></element-citation></ref><ref id="B7-sensors-21-00471"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piria</surname><given-names>M.</given-names></name><name><surname>Copp</surname><given-names>G.H.</given-names></name><name><surname>Dick</surname><given-names>J.T.</given-names></name><name><surname>Dupli&#x00107;</surname><given-names>A.</given-names></name><name><surname>Groom</surname><given-names>Q.</given-names></name><name><surname>Jeli&#x00107;</surname><given-names>D.</given-names></name><name><surname>Lucy</surname><given-names>F.E.</given-names></name><name><surname>Roy</surname><given-names>H.E.</given-names></name><name><surname>Sarat</surname><given-names>E.</given-names></name><name><surname>Simonovi&#x00107;</surname><given-names>P.</given-names></name><etal/></person-group><article-title>Tackling invasive alien species in Europe II: Threats and opportunities until 2020</article-title><source>Manag. Biol. Invasions</source><year>2017</year><volume>8</volume><fpage>273</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.3391/mbi.2017.8.3.02</pub-id></element-citation></ref><ref id="B8-sensors-21-00471"><label>8.</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Hollenbach</surname><given-names>M.</given-names></name></person-group><article-title>Verst&#x000e4;rktes Vorgehen der Naturschutzbeh&#x000f6;rde Gegen Die Nordamerikanische Kulturheidelbeere</article-title><year>2014</year><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://www.nlwkn.niedersachsen.de/naturschutz/fach_und_forderprogramme/life/hannoversche_moorgeest/aktuelles_termine/verstaerktes-vorgehen-der-naturschutzbehoerde-gegen-die-nordamerikanische-kulturheidelbeere-126107.html">https://www.nlwkn.niedersachsen.de/naturschutz/fach_und_forderprogramme/life/hannoversche_moorgeest/aktuelles_termine/verstaerktes-vorgehen-der-naturschutzbehoerde-gegen-die-nordamerikanische-kulturheidelbeere-126107.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2020-11-11">(accessed on 11 November 2020)</date-in-citation></element-citation></ref><ref id="B9-sensors-21-00471"><label>9.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schepker</surname><given-names>H.</given-names></name><name><surname>Kowarik</surname><given-names>I.</given-names></name></person-group><article-title>Invasive North American Blueberry Hybrids (<italic>Vaccinium corymbosum</italic> x <italic>angustifolium</italic>) in Northern Germany</article-title><source>Plant Invasions: Ecological Mechanisms and Human Responses</source><publisher-name>Backhuys Publishers</publisher-name><publisher-loc>Leiden, The Netherlands</publisher-loc><year>1998</year><fpage>253</fpage><lpage>260</lpage></element-citation></ref><ref id="B10-sensors-21-00471"><label>10.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Stieper</surname><given-names>L.C.</given-names></name></person-group><article-title>Distribution of Wild Growing Cultivated Blueberries in Kr&#x000e4;henmoor and Their Impact on Bog Vegetation and Bog Development</article-title><source>Bachelor&#x02019;s Thesis</source><publisher-name>Leibniz University of Hannover</publisher-name><publisher-loc>Hanover, Germany</publisher-loc><year>2018</year></element-citation></ref><ref id="B11-sensors-21-00471"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nehring</surname><given-names>S.</given-names></name><name><surname>Kowarik</surname><given-names>I.</given-names></name><name><surname>Rabitsch</surname><given-names>W.</given-names></name><name><surname>Essl</surname><given-names>F.</given-names></name><name><surname>Lippe</surname><given-names>M.</given-names></name><name><surname>Lauterbach</surname><given-names>D.</given-names></name><name><surname>Seitz</surname><given-names>B.</given-names></name><name><surname>Isermann</surname><given-names>M.</given-names></name><name><surname>Etling</surname><given-names>K.</given-names></name></person-group><article-title>Naturschutzfachliche Invasivit&#x000e4;tsbewertungen f&#x000fc;r in Deutschland wild lebende gebietsfremde Gef&#x000e4;&#x000df;pflanzen</article-title><source>BfN-Skripten</source><year>2013</year><volume>352</volume><fpage>1</fpage><lpage>202</lpage></element-citation></ref><ref id="B12-sensors-21-00471"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deilmann</surname><given-names>H.C.</given-names></name><name><surname>Eichhorn</surname><given-names>G.</given-names></name><name><surname>Falkenberg</surname><given-names>H.</given-names></name><name><surname>G&#x000fc;nther</surname><given-names>J.</given-names></name><name><surname>Hayen</surname><given-names>H.</given-names></name><name><surname>Kuntze</surname><given-names>H.</given-names></name><name><surname>Pollak</surname><given-names>E.</given-names></name><name><surname>Schmatzler</surname><given-names>E.</given-names></name><name><surname>Steffens</surname><given-names>P.J.T.</given-names></name></person-group><article-title>Moor und Torf in Niedersachsen</article-title><source>Nieders&#x000e4;chsische Akad. Geowiss.</source><year>1990</year><volume>5</volume><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://www.schweizerbart.de/publications/detail/artno/183010500/Moor-und-Torf-in-Niedersachsen">https://www.schweizerbart.de/publications/detail/artno/183010500/Moor-und-Torf-in-Niedersachsen</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2021-01-11">(accessed on 11 January 2021)</date-in-citation></element-citation></ref><ref id="B13-sensors-21-00471"><label>13.</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Kowarik</surname><given-names>U.S.I.</given-names></name></person-group><article-title><italic>Vaccinium angustifolium</italic> x <italic>corymbosum</italic></article-title><year>2003</year><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://neobiota.bfn.de/handbuch/gefaesspflanzen/vaccinium-angustifolim-x-corymbosum.html">https://neobiota.bfn.de/handbuch/gefaesspflanzen/vaccinium-angustifolim-x-corymbosum.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2020-11-11">(accessed on 11 November 2020)</date-in-citation></element-citation></ref><ref id="B14-sensors-21-00471"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schepker</surname><given-names>H.</given-names></name><name><surname>Kowarik</surname><given-names>I.</given-names></name><name><surname>Grave</surname><given-names>E.</given-names></name></person-group><article-title>Verwilderung nordamerikanischer Kultur-Heidelbeeren (Vaccinium subgen. Cyanococcus) in Niedersachsen und deren Einsch&#x000e4;tzung aus Naturschutzsicht</article-title><source>Nat. Landsch.</source><year>1997</year><volume>72</volume><fpage>346</fpage><lpage>351</lpage></element-citation></ref><ref id="B15-sensors-21-00471"><label>15.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Essl</surname><given-names>F.</given-names></name></person-group><article-title>Erstfund eines verwilderten Vorkommens der Kultur-Heidelbeere (<italic>Vaccinium angustifolium</italic> x <italic>corymbosum</italic>) in &#x000d6;stereich</article-title><source>Linzer Biologische Beitr&#x000e4;ge</source><publisher-loc>Austria</publisher-loc><year>2004</year><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://www.zobodat.at/pdf/LBB_0036_2_0785-0796.pdf">https://www.zobodat.at/pdf/LBB_0036_2_0785-0796.pdf</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2021-01-11">(accessed on 11 January 2021)</date-in-citation></element-citation></ref><ref id="B16-sensors-21-00471"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grenzdorffer</surname><given-names>G.</given-names></name><name><surname>Teichert</surname><given-names>B.</given-names></name></person-group><article-title>The photogrammetric potential of low-cost UAVs in forestry and agriculture</article-title><source>Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.</source><year>2008</year><volume>31</volume><fpage>1207</fpage><lpage>1214</lpage></element-citation></ref><ref id="B17-sensors-21-00471"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raparelli</surname><given-names>E.</given-names></name><name><surname>Bajocco</surname><given-names>S.</given-names></name></person-group><article-title>A bibliometric analysis on the use of unmanned aerial vehicles in agricultural and forestry studies</article-title><source>Int. J. Remote Sens.</source><year>2019</year><volume>40</volume><fpage>9070</fpage><lpage>9083</lpage><pub-id pub-id-type="doi">10.1080/01431161.2019.1569793</pub-id></element-citation></ref><ref id="B18-sensors-21-00471"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Natesan</surname><given-names>S.</given-names></name><name><surname>Armenakis</surname><given-names>C.</given-names></name><name><surname>Vepakomma</surname><given-names>U.</given-names></name></person-group><article-title>Resnet-based tree species classification using UAV images</article-title><source>ISPRS-Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.</source><year>2019</year><volume>XLII-2/W13</volume><fpage>475</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.5194/isprs-archives-XLII-2-W13-475-2019</pub-id></element-citation></ref><ref id="B19-sensors-21-00471"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gambella</surname><given-names>F.</given-names></name><name><surname>Sistu</surname><given-names>L.</given-names></name><name><surname>Piccirilli</surname><given-names>D.</given-names></name><name><surname>Corposanto</surname><given-names>S.</given-names></name><name><surname>Caria</surname><given-names>M.</given-names></name><name><surname>Arcangeletti</surname><given-names>E.</given-names></name><name><surname>Proto</surname><given-names>A.R.</given-names></name><name><surname>Chessa</surname><given-names>G.</given-names></name><name><surname>Pazzona</surname><given-names>A.</given-names></name></person-group><article-title>Forest and UAV: A bibliometric review</article-title><source>Contemp. Eng. Sci.</source><year>2016</year><volume>9</volume><fpage>1359</fpage><lpage>1370</lpage><pub-id pub-id-type="doi">10.12988/ces.2016.68130</pub-id></element-citation></ref><ref id="B20-sensors-21-00471"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kentsch</surname><given-names>S.</given-names></name><name><surname>Lopez Caceres</surname><given-names>M.L.</given-names></name><name><surname>Serrano</surname><given-names>D.</given-names></name><name><surname>Roure</surname><given-names>F.</given-names></name><name><surname>Diez</surname><given-names>Y.</given-names></name></person-group><article-title>Computer Vision and Deep Learning Techniques for the Analysis of Drone-Acquired Forest Images, a Transfer Learning Study</article-title><source>Remote Sens.</source><year>2020</year><volume>12</volume><elocation-id>1287</elocation-id><pub-id pub-id-type="doi">10.3390/rs12081287</pub-id></element-citation></ref><ref id="B21-sensors-21-00471"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heipke</surname><given-names>H.</given-names></name><name><surname>Pakzad</surname><given-names>K.</given-names></name><name><surname>Straub</surname><given-names>B.M.</given-names></name></person-group><article-title>Image Analysis for GIS Data Acquisition</article-title><source>Photogramm. Rec.</source><year>2000</year><volume>16</volume><fpage>963</fpage><lpage>985</lpage><pub-id pub-id-type="doi">10.1111/0031-868X.00160</pub-id></element-citation></ref><ref id="B22-sensors-21-00471"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carlsson</surname><given-names>G.</given-names></name></person-group><article-title>Persistent Homology and Applied Homotopy Theory</article-title><source>arXiv</source><year>2020</year><pub-id pub-id-type="arxiv">math.AT/2004.00738</pub-id></element-citation></ref><ref id="B23-sensors-21-00471"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahdavi</surname><given-names>S.</given-names></name><name><surname>Salehi</surname><given-names>B.</given-names></name><name><surname>Granger</surname><given-names>J.</given-names></name><name><surname>Amani</surname><given-names>M.</given-names></name><name><surname>Brisco</surname><given-names>B.</given-names></name><name><surname>Huang</surname><given-names>W.</given-names></name></person-group><article-title>Remote sensing for wetland classification: A comprehensive review</article-title><source>GISci. Remote Sens.</source><year>2018</year><volume>55</volume><fpage>623</fpage><lpage>658</lpage><pub-id pub-id-type="doi">10.1080/15481603.2017.1419602</pub-id></element-citation></ref><ref id="B24-sensors-21-00471"><label>24.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Q.</given-names></name></person-group><article-title>2.07-GIS and Remote Sensing Applications in Wetland Mapping and Monitoring</article-title><source>Comprehensive Geographic Information Systems</source><person-group person-group-type="editor"><name><surname>Huang</surname><given-names>B.</given-names></name></person-group><publisher-name>Elsevier</publisher-name><publisher-loc>Oxford, UK</publisher-loc><year>2018</year><fpage>140</fpage><lpage>157</lpage></element-citation></ref><ref id="B25-sensors-21-00471"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Twumasi</surname><given-names>Y.A.</given-names></name><name><surname>Merem</surname><given-names>E.C.</given-names></name></person-group><article-title>GIS and Remote Sensing Applications in the Assessment of Change within a Coastal Environment in the Niger Delta Region of Nigeria</article-title><source>Int. J. Environ. Res. Public Health</source><year>2006</year><volume>3</volume><fpage>98</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.3390/ijerph2006030011</pub-id><pub-id pub-id-type="pmid">16823081</pub-id></element-citation></ref><ref id="B26-sensors-21-00471"><label>26.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lang</surname><given-names>S.</given-names></name></person-group><article-title>Object-based image analysis for remote sensing applications: Modeling reality&#x02014;Dealing with complexity</article-title><source>Object-Based Image Analysis</source><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg, Germany</publisher-loc><year>2008</year><fpage>3</fpage><lpage>27</lpage></element-citation></ref><ref id="B27-sensors-21-00471"><label>27.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>C.</given-names></name><name><surname>de Leeuw</surname><given-names>J.</given-names></name><name><surname>van Duren</surname><given-names>I.</given-names></name></person-group><article-title>Remote sensing and GIS applications for mapping and spatial modelling of invasive species</article-title><source>Proceedings of the XXth ISPRS Congress: Geo-Imagery Bridging Continents</source><conf-loc>Istanbul, Turkey</conf-loc><conf-date>12&#x02013;23 July 2004</conf-date><fpage>669</fpage><lpage>677</lpage></element-citation></ref><ref id="B28-sensors-21-00471"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rebelo</surname><given-names>L.M.</given-names></name><name><surname>Finlayson</surname><given-names>C.</given-names></name><name><surname>Nagabhatla</surname><given-names>N.</given-names></name></person-group><article-title>Remote sensing and GIS for wetland inventory, mapping and change analysis</article-title><source>J. Environ. Manag.</source><year>2009</year><volume>90</volume><fpage>2144</fpage><lpage>2153</lpage><pub-id pub-id-type="doi">10.1016/j.jenvman.2007.06.027</pub-id></element-citation></ref><ref id="B29-sensors-21-00471"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gandhi</surname><given-names>G.M.</given-names></name><name><surname>Parthiban</surname><given-names>S.</given-names></name><name><surname>Thummalu</surname><given-names>N.</given-names></name><name><surname>Christy</surname><given-names>A.</given-names></name></person-group><article-title>Ndvi: Vegetation Change Detection Using Remote Sensing and Gis&#x02014;A Case Study of Vellore District</article-title><source>Procedia Comput. Sci.</source><year>2015</year><volume>57</volume><fpage>1199</fpage><lpage>1210</lpage><pub-id pub-id-type="doi">10.1016/j.procs.2015.07.415</pub-id></element-citation></ref><ref id="B30-sensors-21-00471"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dronova</surname><given-names>I.</given-names></name></person-group><article-title>Object-Based Image Analysis in Wetland Research: A Review</article-title><source>Remote Sens.</source><year>2015</year><volume>7</volume><fpage>6380</fpage><lpage>6413</lpage><pub-id pub-id-type="doi">10.3390/rs70506380</pub-id></element-citation></ref><ref id="B31-sensors-21-00471"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>T&#x000f3;thm&#x000e9;r&#x000e9;sz</surname><given-names>B.</given-names></name><name><surname>Wan</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>Q.</given-names></name><name><surname>Jiang</surname><given-names>D.</given-names></name><name><surname>Fu</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name></person-group><article-title>Monitoring the Invasion of Spartina alterniflora Using Very High Resolution Unmanned Aerial Vehicle Imagery in Beihai, Guangxi (China)</article-title><source>Sci. World J.</source><year>2014</year><volume>2014</volume><fpage>638296</fpage></element-citation></ref><ref id="B32-sensors-21-00471"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boon</surname><given-names>M.</given-names></name><name><surname>Greenfield</surname><given-names>R.</given-names></name><name><surname>Tesfamichael</surname><given-names>S.</given-names></name></person-group><article-title>Wetland assessment using unmanned aerial vehicle (UAV) photogrammetry</article-title><source>ISPRS-Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.</source><year>2016</year><volume>XLI-B1</volume><fpage>781</fpage><lpage>788</lpage><pub-id pub-id-type="doi">10.5194/isprsarchives-XLI-B1-781-2016</pub-id></element-citation></ref><ref id="B33-sensors-21-00471"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boon</surname><given-names>M.</given-names></name><name><surname>Greenfield</surname><given-names>R.</given-names></name><name><surname>Tesfamichael</surname><given-names>S.</given-names></name></person-group><article-title>Unmanned Aerial Vehicle (UAV) photogrammetry produces accurate high-resolution orthophotos, point clouds and surface models for mapping wetlands</article-title><source>South Afr. J. Geomat.</source><year>2016</year><volume>5</volume><fpage>186</fpage><pub-id pub-id-type="doi">10.4314/sajg.v5i2.7</pub-id></element-citation></ref><ref id="B34-sensors-21-00471"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dvo&#x00159;&#x000e1;k</surname><given-names>P.</given-names></name><name><surname>M&#x000fc;llerov&#x000e1;</surname><given-names>J.</given-names></name><name><surname>Bartalo&#x00161;</surname><given-names>T.</given-names></name><name><surname>Br&#x0016f;na</surname><given-names>J.</given-names></name></person-group><article-title>Unmanned aerial vehicles for alien plant species detection and monitoring</article-title><source>Remote Sens. Spat. Inf. Sci.</source><year>2015</year><volume>XL-1/W42015</volume><pub-id pub-id-type="doi">10.5194/isprsarchives-XL-1-W4-83-2015</pub-id></element-citation></ref><ref id="B35-sensors-21-00471"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mafanya</surname><given-names>M.</given-names></name><name><surname>Tsele</surname><given-names>P.</given-names></name><name><surname>Botai</surname><given-names>J.</given-names></name><name><surname>Manyama</surname><given-names>P.</given-names></name><name><surname>Swart</surname><given-names>B.</given-names></name><name><surname>Monate</surname><given-names>T.</given-names></name></person-group><article-title>Evaluating pixel and object based image classification techniques for mapping plant invasions from UAV derived aerial imagery: Harrisia pomanensis as a case study</article-title><source>ISPRS J. Photogramm. Remote Sens.</source><year>2017</year><volume>129</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2017.04.009</pub-id></element-citation></ref><ref id="B36-sensors-21-00471"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rezaee</surname><given-names>M.</given-names></name><name><surname>Mahdianpari</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Salehi</surname><given-names>B.</given-names></name></person-group><article-title>Deep Convolutional Neural Network for Complex Wetland Classification Using Optical Remote Sensing Imagery</article-title><source>IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.</source><year>2018</year><volume>11</volume><fpage>3030</fpage><lpage>3039</lpage><pub-id pub-id-type="doi">10.1109/JSTARS.2018.2846178</pub-id></element-citation></ref><ref id="B37-sensors-21-00471"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>T.</given-names></name><name><surname>Abd-Elrahman</surname><given-names>A.</given-names></name></person-group><article-title>Deep convolutional neural network training enrichment using multi-view object-based analysis of Unmanned Aerial systems imagery for wetlands classification</article-title><source>ISPRS J. Photogramm. Remote Sens.</source><year>2018</year><volume>139</volume><fpage>154</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2018.03.006</pub-id></element-citation></ref><ref id="B38-sensors-21-00471"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashqar</surname><given-names>B.</given-names></name><name><surname>Abu-Naser</surname><given-names>S.</given-names></name></person-group><article-title>Identifying Images of Invasive Hydrangea Using Pre-Trained Deep Convolutional Neural Networks</article-title><source>Int. J. Acad. Dev.</source><year>2019</year><volume>3</volume><fpage>28</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.33832/ijca.2019.12.4.02</pub-id></element-citation></ref><ref id="B39-sensors-21-00471"><label>39.</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Schneekloth</surname><given-names>H.</given-names></name><name><surname>Tuexen</surname><given-names>J.</given-names></name></person-group><article-title>Die Moore in Niedersachsen. GOTTINGEN Kommissionsverl. Goettinger Tageblatt, 1975, P. 1 A 198</article-title><year>1975</year><comment>Available online: <ext-link ext-link-type="uri" xlink:href="http://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&#x00026;idt=PASCALGEODEBRGM7620141242">http://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&#x00026;idt=PASCALGEODEBRGM7620141242</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2021-01-08">(accessed on 8 January 2021)</date-in-citation></element-citation></ref><ref id="B40-sensors-21-00471"><label>40.</label><element-citation publication-type="web"><person-group person-group-type="author"><collab>Agisoft</collab></person-group><article-title>Agisoft Metashape 1.5.5, Professional Edition</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="http://www.agisoft.com/downloads/installer/">http://www.agisoft.com/downloads/installer/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2019-08-19">(accessed on 19 August 2019)</date-in-citation></element-citation></ref><ref id="B41-sensors-21-00471"><label>41.</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Team</surname><given-names>T.G.</given-names></name></person-group><article-title>GNU Image Manipulation Program</article-title><comment>Available online: <ext-link ext-link-type="uri" xlink:href="http://gimp.org">http://gimp.org</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2019-08-19">(accessed on 19 August 2019)</date-in-citation></element-citation></ref><ref id="B42-sensors-21-00471"><label>42.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Asaad</surname><given-names>A.</given-names></name></person-group><article-title>Persistent Homology for Image Analysis</article-title><source>Ph.D. Thesis</source><publisher-name>University of Buckingham</publisher-name><publisher-loc>Buckingham, UK</publisher-loc><year>2020</year></element-citation></ref><ref id="B43-sensors-21-00471"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cabezas</surname><given-names>M.</given-names></name><name><surname>Kentsch</surname><given-names>S.</given-names></name><name><surname>Tomhave</surname><given-names>L.</given-names></name><name><surname>Gross</surname><given-names>J.</given-names></name><name><surname>Caceres</surname><given-names>M.L.L.</given-names></name><name><surname>Diez</surname><given-names>Y.</given-names></name></person-group><article-title>Detection of Invasive Species in Wetlands: Practical DL with Heavily Imbalanced Data</article-title><source>Remote Sens.</source><year>2020</year><volume>12</volume><elocation-id>3431</elocation-id><pub-id pub-id-type="doi">10.3390/rs12203431</pub-id></element-citation></ref><ref id="B44-sensors-21-00471"><label>44.</label><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>A.B.</given-names></name><name><surname>Wada</surname><given-names>K.</given-names></name><name><surname>Crall</surname><given-names>J.</given-names></name><name><surname>Tanaka</surname><given-names>S.</given-names></name><name><surname>Graving</surname><given-names>J.</given-names></name><name><surname>Reinders</surname><given-names>C.</given-names></name><name><surname>Yadav</surname><given-names>S.</given-names></name><name><surname>Banerjee</surname><given-names>J.</given-names></name><name><surname>Vecsei</surname><given-names>G.</given-names></name><name><surname>Kraft</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Imgaug</article-title><year>2020</year><comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://github.com/aleju/imgaug">https://github.com/aleju/imgaug</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2020-07-01">(accessed on 1 July 2020)</date-in-citation></element-citation></ref><ref id="B45-sensors-21-00471"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name><name><surname>Hinton</surname><given-names>G.E.</given-names></name></person-group><article-title>ImageNet Classification with Deep Convolutional Neural Networks</article-title><source>Commun. ACM</source><year>2017</year><volume>60</volume><fpage>84</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1145/3065386</pub-id></element-citation></ref><ref id="B46-sensors-21-00471"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patrick</surname><given-names>A.</given-names></name><name><surname>Li</surname><given-names>C.</given-names></name></person-group><article-title>High Throughput Phenotyping of Blueberry Bush Morphological Traits Using Unmanned Aerial Systems</article-title><source>Remote Sens.</source><year>2017</year><volume>9</volume><elocation-id>1250</elocation-id><pub-id pub-id-type="doi">10.3390/rs9121250</pub-id></element-citation></ref><ref id="B47-sensors-21-00471"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zmarz</surname><given-names>A.</given-names></name></person-group><article-title>UAV&#x02014;A useful tool for monitoring woodlands</article-title><source>Misc. Geogr.&#x02013;Reg. Stud. Dev.</source><year>2013</year><volume>18</volume><fpage>46</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.2478/mgrsd-2014-0006</pub-id></element-citation></ref><ref id="B48-sensors-21-00471"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wierzbicki</surname><given-names>D.</given-names></name><name><surname>Kedzierski</surname><given-names>M.</given-names></name><name><surname>Fryskowska</surname><given-names>A.</given-names></name></person-group><article-title>Assesment of the influence of uav image quality on the orthophoto production</article-title><source>ISPRS-Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.</source><year>2015</year><volume>XL-1/W4</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.5194/isprsarchives-XL-1-W4-1-2015</pub-id></element-citation></ref><ref id="B49-sensors-21-00471"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dandois</surname><given-names>J.P.</given-names></name><name><surname>Olano</surname><given-names>M.</given-names></name><name><surname>Ellis</surname><given-names>E.C.</given-names></name></person-group><article-title>Optimal Altitude, Overlap, and Weather Conditions for Computer Vision UAV Estimates of Forest Structure</article-title><source>Remote Sens.</source><year>2015</year><volume>7</volume><fpage>13895</fpage><lpage>13920</lpage><pub-id pub-id-type="doi">10.3390/rs71013895</pub-id></element-citation></ref><ref id="B50-sensors-21-00471"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frey</surname><given-names>J.</given-names></name><name><surname>Kovach</surname><given-names>K.</given-names></name><name><surname>Stemmler</surname><given-names>S.</given-names></name><name><surname>Koch</surname><given-names>B.</given-names></name></person-group><article-title>UAV Photogrammetry of Forests as a Vulnerable Process. A Sensitivity Analysis for a Structure from Motion RGB-Image Pipeline</article-title><source>Remote Sens.</source><year>2018</year><volume>10</volume><elocation-id>912</elocation-id><pub-id pub-id-type="doi">10.3390/rs10060912</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="sensors-21-00471-f001" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Location of the study area in the north of Germany. In the upper right part of the figure, the study sites are marked with different colours. The bottom right part an example orthomosaic is shown with detail of the different classes.</p></caption><graphic xlink:href="sensors-21-00471-g001"/></fig><fig id="sensors-21-00471-f002" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Workflow of the paper. Gray is our data base; purple boxes show softwares/programs used in this study; white boxes with a blue outline are generated files; dark blue are processes used for the deep learning (DL) classification and detection; light blue are tools in ArcGIS.</p></caption><graphic xlink:href="sensors-21-00471-g002"/></fig><fig id="sensors-21-00471-f003" orientation="portrait" position="float"><label>Figure 3</label><caption><p>Image analysis workflow. Consists of two parts, the manual approach using manual annotation, GIS and persistent homology, and the automatic approach while using deep learning and segmentation to analyse the blueberry invasion.</p></caption><graphic xlink:href="sensors-21-00471-g003"/></fig><fig id="sensors-21-00471-f004" orientation="portrait" position="float"><label>Figure 4</label><caption><p>Distribution of annotated classes for the orthomosaics B1 to B3.</p></caption><graphic xlink:href="sensors-21-00471-g004"/></fig><fig id="sensors-21-00471-f005" orientation="portrait" position="float"><label>Figure 5</label><caption><p>Distribution of the area and height values of blueberry bushes. From top to bottom: area, maximum height, and median height.</p></caption><graphic xlink:href="sensors-21-00471-g005"/></fig><fig id="sensors-21-00471-f006" orientation="portrait" position="float"><label>Figure 6</label><caption><p>Density map for the blueberry species for the sites B1 to B3 (location see <xref ref-type="fig" rid="sensors-21-00471-f001">Figure 1</xref>). Areas of low densities are marked in green and high densities are red coloured. A gradient between green and red represents values of medium density. White points mark the location of the blueberry bushes.</p></caption><graphic xlink:href="sensors-21-00471-g006"/></fig><fig id="sensors-21-00471-f007" orientation="portrait" position="float"><label>Figure 7</label><caption><p>The persistent homology is plotted by radius against the region. Four fused regions were considered: 1%, 10%, 50%, and 90% and all sites are plotted.</p></caption><graphic xlink:href="sensors-21-00471-g007"/></fig><fig id="sensors-21-00471-f008" orientation="portrait" position="float"><label>Figure 8</label><caption><p>Orthomosaic B1 is displayed with a combination of the manual annotations (black marked spots), the coarse mask (dark grey) and the refined mask (light grey). The red box was zoomed in to show a detailed view on the image and masks.</p></caption><graphic xlink:href="sensors-21-00471-g008"/></fig><table-wrap id="sensors-21-00471-t001" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-21-00471-t001_Table 1</object-id><label>Table 1</label><caption><p>Area and counting measures of blueberry bushes detected in the orthomosaics.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Orthomosaic Area in ha</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Number of Blueberry Bushes</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Blueberry Bushes per ha</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Blueberry Bush Area in m<inline-formula><mml:math id="mm32"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mstyle></mml:mrow></mml:math></inline-formula></th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Area per Blueberry Bush in m<inline-formula><mml:math id="mm33"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mstyle></mml:mrow></mml:math></inline-formula></th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">B1</td><td align="center" valign="middle" rowspan="1" colspan="1">11.64</td><td align="center" valign="middle" rowspan="1" colspan="1">375</td><td align="center" valign="middle" rowspan="1" colspan="1">32.21</td><td align="center" valign="middle" rowspan="1" colspan="1">1331.42</td><td align="center" valign="middle" rowspan="1" colspan="1">3.55</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">B2</td><td align="center" valign="middle" rowspan="1" colspan="1">10.64</td><td align="center" valign="middle" rowspan="1" colspan="1">687</td><td align="center" valign="middle" rowspan="1" colspan="1">64.55</td><td align="center" valign="middle" rowspan="1" colspan="1">1885.51</td><td align="center" valign="middle" rowspan="1" colspan="1">2.74</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">B3</td><td align="center" valign="middle" rowspan="1" colspan="1">12.47</td><td align="center" valign="middle" rowspan="1" colspan="1">566</td><td align="center" valign="middle" rowspan="1" colspan="1">45.40</td><td align="center" valign="middle" rowspan="1" colspan="1">1470.24</td><td align="center" valign="middle" rowspan="1" colspan="1">2.60</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">B4</td><td align="center" valign="middle" rowspan="1" colspan="1">12.44</td><td align="center" valign="middle" rowspan="1" colspan="1">405</td><td align="center" valign="middle" rowspan="1" colspan="1">32.54</td><td align="center" valign="middle" rowspan="1" colspan="1">870.33</td><td align="center" valign="middle" rowspan="1" colspan="1">2.15</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">B6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.14</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">235</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.53</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">278.07</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.18</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr></tbody></table></table-wrap><table-wrap id="sensors-21-00471-t002" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-21-00471-t002_Table 2</object-id><label>Table 2</label><caption><p>Clustering results that are based on point shapefiles of the sites.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">3 m Clustering</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">6 m Clustering</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Grouped 3<break/>
or More (in %)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Number of<break/>
Single Bushes</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Highest Count<break/>
in One Group</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Grouped 3<break/>
or More (in %)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Number of <break/>
Single Bushes</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Highest Count<break/>
in One Group</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">B1</td><td align="center" valign="middle" rowspan="1" colspan="1">39.87</td><td align="center" valign="middle" rowspan="1" colspan="1">89</td><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">56.63</td><td align="center" valign="middle" rowspan="1" colspan="1">18</td><td align="center" valign="middle" rowspan="1" colspan="1">25</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">B2</td><td align="center" valign="middle" rowspan="1" colspan="1">36.82</td><td align="center" valign="middle" rowspan="1" colspan="1">87</td><td align="center" valign="middle" rowspan="1" colspan="1">25</td><td align="center" valign="middle" rowspan="1" colspan="1">69.57</td><td align="center" valign="middle" rowspan="1" colspan="1">23</td><td align="center" valign="middle" rowspan="1" colspan="1">50</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">B3</td><td align="center" valign="middle" rowspan="1" colspan="1">35.51</td><td align="center" valign="middle" rowspan="1" colspan="1">98</td><td align="center" valign="middle" rowspan="1" colspan="1">33</td><td align="center" valign="middle" rowspan="1" colspan="1">50.43</td><td align="center" valign="middle" rowspan="1" colspan="1">36</td><td align="center" valign="middle" rowspan="1" colspan="1">50</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">B4</td><td align="center" valign="middle" rowspan="1" colspan="1">28.34</td><td align="center" valign="middle" rowspan="1" colspan="1">92</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">44.35</td><td align="center" valign="middle" rowspan="1" colspan="1">39</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">B6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">28.28</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">51</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">37.68</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">28</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21</td></tr></tbody></table></table-wrap><table-wrap id="sensors-21-00471-t003" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-21-00471-t003_Table 3</object-id><label>Table 3</label><caption><p>Numerical evaluation of the refinement step of the DNN. The rows marked "refined" stand for the algorithm after refinement, while the rows marked "Coarse" correspond to the algorithm without refinement for each of the three studied orthomosaics. The Dice coefficient, as well as the ratio of blueberry pixels in the Ground truth covered by each of the two masks, are presented.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Orthomosaic</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Mask Type</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Dice</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">GT Cover</th></tr></thead><tbody><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Coarse</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.187</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.953</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Refined</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.526</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.860</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Coarse</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.264</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.949</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Refined</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.624</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.874</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Coarse</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.223</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.884</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Refined</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.587</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.789</td></tr></tbody></table></table-wrap></floats-group></article>