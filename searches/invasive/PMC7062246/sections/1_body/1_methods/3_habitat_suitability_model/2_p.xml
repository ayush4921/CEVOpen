<?xml version="1.0" encoding="UTF-8"?>
<p>Each model was evaluated using a 10-fold cross-validation approach [
 <xref rid="pone.0229253.ref048" ref-type="bibr">48</xref>], which partitions the training data into 10 equal subsets and runs 10 model iterations where 9 subsets are used for model development (training data) and the final subset is used to test the model performance (test data). The 10 iterations are then averaged together to provide a final measure of model performance. SAHM produces several statistical measures (‘Generate Model Statistics’, 
 <xref ref-type="fig" rid="pone.0229253.g001">Fig 1</xref>) including AUC-ROC, AUC-precision recall (AUC-PR), Kappa, True Skill Statistic (TSS), percent correctly classified (PCC), sensitivity, and specificity which we compiled for each model on the training and test data to evaluate performance. These metrics together can help evaluate the quality of a model and generally a model with a test AUC value &gt;0.7 is considered to have good performance and can be useful [
 <xref rid="pone.0229253.ref049" ref-type="bibr">49</xref>].
</p>
