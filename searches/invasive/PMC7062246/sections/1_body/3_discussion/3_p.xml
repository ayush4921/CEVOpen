<?xml version="1.0" encoding="UTF-8"?>
<p>We developed our models with Sofaer et al.’s [
 <xref rid="pone.0229253.ref012" ref-type="bibr">12</xref>] model assessment rubric in mind and evaluated our models using this framework (
 <xref rid="pone.0229253.t004" ref-type="table">Table 4</xref>). Our models consistently scored in the ‘acceptable practices’ category with a few metrics scoring as ‘ideal’ (‘interpretation support products’ and ‘reproducibility’) and two as ‘interpret with caution’ (‘model review’ for goutweed and ‘iterative’ for both; the latter is by design as we were interested in defining an entry point for iterative modeling). For many models, it would be impossible to score ‘ideal’ using readily available data rather than data collected based on a statistically designed study for the specific species. The ‘interpret with caution’ categories could move to ‘acceptable practices’ with a second iteration. As the model results are evaluated and used in the field, additional data will be provided and practitioners and experts will also have an opportunity to review and evaluate the model results. Further, our model results provide a ranking of the environmental variable contribution to the model combined with figures of the response curves (Table B and Figure A in 
 <xref ref-type="supplementary-material" rid="pone.0229253.s001">S1 File</xref>). Compiling and presenting these results not only inform the modelers what factors may be important and how the species may respond to those factors but also serve as an important resource for practitioners and species experts to evaluate the model credibility. This can provide another aspect of model validation or enable model iteration and improvement.
</p>
